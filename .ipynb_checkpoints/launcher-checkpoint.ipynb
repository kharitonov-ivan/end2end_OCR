{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make: Entering directory '/home/dmivanov/end2end_OCR/utils/lanms'\n",
      "make: 'adaptor.so' is up to date.\n",
      "make: Leaving directory '/home/dmivanov/end2end_OCR/utils/lanms'\n",
      "args config\n",
      "{'name': 'FOTS', 'cuda': True, 'gpus': ['4'], 'finetune': '/data/ivpaharitonov/checkpoints/saved_icdar_2017/FOTS/checkpoint-epoch015-loss-1.9341.pth.tar', 'data_loader': {'___dataset': 'icdar2015', 'dataset': 'icdar2017', '_dataset': 'synth80k', '__data_dir': '/data/ivpaharitonov/SynthText/SynthText/', 'data_dir': '/data/ivpaharitonov/ocr_datasets/ICDAR2017/', '_data_dir': '/data/ivpaharitonov/icdar2015/ICDAR2015/', '-data_dir': '/Users/ivan_kharitonov/Google Drive/End2end_text_recognition_YSDA/datasets/SynthText/SynthText/', 'batch_size': 4, 'shuffle': True, 'workers': 8}, 'validation': {'validation_split': 0.2, 'shuffle': True}, 'lr_scheduler_type': 'ExponentialLR', 'lr_scheduler_freq': 3, 'lr_scheduler': {'gamma': 0.94}, 'optimizer_type': 'Adam', 'optimizer': {'lr': 0.001, 'weight_decay': 1e-05}, 'loss': 'FOTSLoss', '_metrics': ['detection_metric'], 'metrics': ['fots_metric'], 'trainer': {'epochs': 100000, 'save_dir': './checkpoints/1-after_2017_unfreeze_resnet', 'save_freq': 10, 'verbosity': 2, 'monitor': 'loss', 'monitor_mode': 'min'}, 'arch': 'FOTSModel', 'need_grad_backbone': True, 'need_grad_detector': True, 'roi_rotate': True, 'loss_coeff': 0.001, 'rectifier': False, 'model': {'gt_to_rec': True, 'get_weights_for': ['conv_det', 'detector', 'conv_rec', 'recognizer'], 'mode': 'united', '_mode': 'recognition', 'keys': 'alphabet_and_number', 'crnn': {'img_h': 16, 'hidden': 1024}}}\n",
      "LOAD GT\n",
      "100%|█████████████████████████████████████| 7167/7167 [00:00<00:00, 9235.95it/s]\n",
      "Trainable parameters: 26205640\n",
      "SharedConv(\n",
      "  (backbone): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): None\n",
      "    (last_linear): Linear(in_features=2048, out_features=1000, bias=True)\n",
      "  )\n",
      "  (mergeLayers0): DummyLayer()\n",
      "  (mergeLayers1): HLayer(\n",
      "    (conv2dOne): Conv2d(3072, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (bnOne): BatchNorm2d(128, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
      "    (conv2dTwo): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bnTwo): BatchNorm2d(128, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (mergeLayers2): HLayer(\n",
      "    (conv2dOne): Conv2d(640, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (bnOne): BatchNorm2d(64, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
      "    (conv2dTwo): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bnTwo): BatchNorm2d(64, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (mergeLayers3): HLayer(\n",
      "    (conv2dOne): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (bnOne): BatchNorm2d(32, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
      "    (conv2dTwo): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bnTwo): BatchNorm2d(32, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (mergeLayers4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn5): BatchNorm2d(32, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
      ")\n",
      "Trainable parameters: 198\n",
      "Detector(\n",
      "  (scoreMap): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (geoMap): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (angleMap): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Trainable parameters: 26205640\n",
      "SharedConv(\n",
      "  (backbone): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): None\n",
      "    (last_linear): Linear(in_features=2048, out_features=1000, bias=True)\n",
      "  )\n",
      "  (mergeLayers0): DummyLayer()\n",
      "  (mergeLayers1): HLayer(\n",
      "    (conv2dOne): Conv2d(3072, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (bnOne): BatchNorm2d(128, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
      "    (conv2dTwo): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bnTwo): BatchNorm2d(128, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (mergeLayers2): HLayer(\n",
      "    (conv2dOne): Conv2d(640, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (bnOne): BatchNorm2d(64, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
      "    (conv2dTwo): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bnTwo): BatchNorm2d(64, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (mergeLayers3): HLayer(\n",
      "    (conv2dOne): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (bnOne): BatchNorm2d(32, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
      "    (conv2dTwo): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bnTwo): BatchNorm2d(32, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (mergeLayers4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn5): BatchNorm2d(32, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
      ")\n",
      "Trainable parameters: 9969039\n",
      "Recognizer(\n",
      "  (crnn): CRNN(\n",
      "    (cnn): Sequential(\n",
      "      (conv0): Conv2d(32, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (batchnorm0): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu0): ReLU(inplace)\n",
      "      (conv1): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (batchnorm1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (HeightMaxPooling0): HeightMaxPool(\n",
      "        (pooling): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (conv2): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (batchnorm2): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv3): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (batchnorm3): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu3): ReLU(inplace)\n",
      "      (HeightMaxPooling1): HeightMaxPool(\n",
      "        (pooling): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (conv4): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (batchnorm4): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu4): ReLU(inplace)\n",
      "      (conv5): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (batchnorm5): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu5): ReLU(inplace)\n",
      "      (HeightMaxPooling2): HeightMaxPool(\n",
      "        (pooling): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "    )\n",
      "    (rnn): BidirectionalLSTM(\n",
      "      (rnn): LSTM(144, 1024, bidirectional=True)\n",
      "      (embedding): Linear(in_features=2048, out_features=63, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "ERROR\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is initialized.\n",
      "Memory Usage: \n",
      "    CUDA: 4  Allocated: 140.87744140625 MB Cached: 178.5 MB \n",
      "\n",
      "Loading checkpoint: /data/ivpaharitonov/checkpoints/saved_icdar_2017/FOTS/checkpoint-epoch015-loss-1.9341.pth.tar ...\n",
      "{'name': 'FOTS', 'cuda': True, 'gpus': ['4'], 'finetune': '/data/ivpaharitonov/checkpoints/saved_icdar_2017/FOTS/checkpoint-epoch015-loss-1.9341.pth.tar', 'data_loader': {'___dataset': 'icdar2015', 'dataset': 'icdar2017', '_dataset': 'synth80k', '__data_dir': '/data/ivpaharitonov/SynthText/SynthText/', 'data_dir': '/data/ivpaharitonov/ocr_datasets/ICDAR2017/', '_data_dir': '/data/ivpaharitonov/icdar2015/ICDAR2015/', '-data_dir': '/Users/ivan_kharitonov/Google Drive/End2end_text_recognition_YSDA/datasets/SynthText/SynthText/', 'batch_size': 4, 'shuffle': True, 'workers': 8}, 'validation': {'validation_split': 0.2, 'shuffle': True}, 'lr_scheduler_type': 'ExponentialLR', 'lr_scheduler_freq': 3, 'lr_scheduler': {'gamma': 0.94}, 'optimizer_type': 'Adam', 'optimizer': {'lr': 0.001, 'weight_decay': 1e-05}, 'loss': 'FOTSLoss', '_metrics': ['detection_metric'], 'metrics': ['fots_metric'], 'trainer': {'epochs': 100000, 'save_dir': './checkpoints/1-after_2017_unfreeze_resnet', 'save_freq': 10, 'verbosity': 2, 'monitor': 'loss', 'monitor_mode': 'min'}, 'arch': 'FOTSModel', 'need_grad_backbone': True, 'need_grad_detector': True, 'roi_rotate': True, 'loss_coeff': 0.001, 'rectifier': False, 'model': {'gt_to_rec': True, 'get_weights_for': ['conv_det', 'detector', 'conv_rec', 'recognizer'], 'mode': 'united', '_mode': 'recognition', 'keys': 'alphabet_and_number', 'crnn': {'img_h': 16, 'hidden': 1024}}}\n",
      "Train Epoch: 1 [0/4412 (0%)] Loss: 1.566077 Detection Loss: 0.020847 Recognition Loss:1.545229\n",
      "Train Epoch: 1 [8/4412 (0%)] Loss: 4.592439 Detection Loss: 0.018407 Recognition Loss:4.574032\n",
      "Train Epoch: 1 [16/4412 (0%)] Loss: 4.002180 Detection Loss: 0.022612 Recognition Loss:3.979568\n",
      "Train Epoch: 1 [24/4412 (1%)] Loss: 4.232285 Detection Loss: 0.044627 Recognition Loss:4.187657\n",
      "Train Epoch: 1 [32/4412 (1%)] Loss: 3.594976 Detection Loss: 0.038834 Recognition Loss:3.556142\n",
      "Train Epoch: 1 [40/4412 (1%)] Loss: 4.193298 Detection Loss: 0.080276 Recognition Loss:4.113023\n",
      "Train Epoch: 1 [48/4412 (1%)] Loss: 3.425510 Detection Loss: 0.036246 Recognition Loss:3.389265\n",
      "Train Epoch: 1 [56/4412 (1%)] Loss: 3.384234 Detection Loss: 0.036213 Recognition Loss:3.348022\n",
      "Train Epoch: 1 [64/4412 (1%)] Loss: 3.947490 Detection Loss: 0.043417 Recognition Loss:3.904073\n",
      "invalid poly\n",
      "Train Epoch: 1 [72/4412 (2%)] Loss: 2.670951 Detection Loss: 0.020102 Recognition Loss:2.650850\n",
      "Train Epoch: 1 [80/4412 (2%)] Loss: 3.863166 Detection Loss: 0.021917 Recognition Loss:3.841249\n",
      "Train Epoch: 1 [88/4412 (2%)] Loss: 3.435995 Detection Loss: 0.051133 Recognition Loss:3.384862\n",
      "Train Epoch: 1 [96/4412 (2%)] Loss: 4.051791 Detection Loss: 0.026324 Recognition Loss:4.025467\n",
      "Train Epoch: 1 [104/4412 (2%)] Loss: 3.486939 Detection Loss: 0.013189 Recognition Loss:3.473749\n",
      "Train Epoch: 1 [112/4412 (3%)] Loss: 3.140378 Detection Loss: 0.035398 Recognition Loss:3.104980\n",
      "Train Epoch: 1 [120/4412 (3%)] Loss: 2.478922 Detection Loss: 0.037752 Recognition Loss:2.441170\n",
      "Train Epoch: 1 [128/4412 (3%)] Loss: 3.108238 Detection Loss: 0.050392 Recognition Loss:3.057846\n",
      "Train Epoch: 1 [136/4412 (3%)] Loss: 3.118354 Detection Loss: 0.021058 Recognition Loss:3.097297\n",
      "Train Epoch: 1 [144/4412 (3%)] Loss: 3.095438 Detection Loss: 0.037725 Recognition Loss:3.057713\n",
      "Train Epoch: 1 [152/4412 (3%)] Loss: 4.393056 Detection Loss: 0.024677 Recognition Loss:4.368379\n",
      "Train Epoch: 1 [160/4412 (4%)] Loss: 3.405665 Detection Loss: 0.043394 Recognition Loss:3.362271\n",
      "Train Epoch: 1 [168/4412 (4%)] Loss: 3.590036 Detection Loss: 0.029032 Recognition Loss:3.561004\n",
      "Train Epoch: 1 [176/4412 (4%)] Loss: 2.886966 Detection Loss: 0.027254 Recognition Loss:2.859712\n",
      "Train Epoch: 1 [184/4412 (4%)] Loss: 3.483353 Detection Loss: 0.056791 Recognition Loss:3.426562\n",
      "Train Epoch: 1 [192/4412 (4%)] Loss: 4.039242 Detection Loss: 0.019852 Recognition Loss:4.019390\n",
      "Train Epoch: 1 [200/4412 (5%)] Loss: 2.669376 Detection Loss: 0.021850 Recognition Loss:2.647526\n",
      "/home/dmivanov/end2end_OCR/data_loader/datautils.py:234: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.linalg.norm(np.cross(p2 - p1, p1 - p3)) / np.linalg.norm(p2 - p1)\n",
      "Cross point does not exist\n",
      "Cross point does not exist\n",
      "Cross point does not exist\n",
      "Cross point does not exist\n",
      "Train Epoch: 1 [208/4412 (5%)] Loss: 4.336549 Detection Loss: 0.037278 Recognition Loss:4.299271\n",
      "Train Epoch: 1 [216/4412 (5%)] Loss: 2.498005 Detection Loss: 0.034199 Recognition Loss:2.463806\n",
      "Train Epoch: 1 [224/4412 (5%)] Loss: 3.569786 Detection Loss: 0.058313 Recognition Loss:3.511473\n",
      "Train Epoch: 1 [232/4412 (5%)] Loss: 3.389914 Detection Loss: 0.068770 Recognition Loss:3.321144\n",
      "Train Epoch: 1 [240/4412 (5%)] Loss: 3.697779 Detection Loss: 0.020319 Recognition Loss:3.677461\n",
      "/home/dmivanov/end2end_OCR/data_loader/datautils.py:234: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.linalg.norm(np.cross(p2 - p1, p1 - p3)) / np.linalg.norm(p2 - p1)\n",
      "Train Epoch: 1 [248/4412 (6%)] Loss: 3.187846 Detection Loss: 0.021454 Recognition Loss:3.166392\n",
      "Train Epoch: 1 [256/4412 (6%)] Loss: 3.069926 Detection Loss: 0.030119 Recognition Loss:3.039807\n",
      "Train Epoch: 1 [264/4412 (6%)] Loss: 3.091126 Detection Loss: 0.034171 Recognition Loss:3.056954\n",
      "Train Epoch: 1 [272/4412 (6%)] Loss: 3.229770 Detection Loss: 0.023436 Recognition Loss:3.206334\n",
      "Train Epoch: 1 [280/4412 (6%)] Loss: 3.970662 Detection Loss: 0.036439 Recognition Loss:3.934223\n",
      "^C\n",
      "['img_2319.jpg', 'img_6371.jpg', 'img_1797.jpg', 'img_1120.jpg']\n"
     ]
    }
   ],
   "source": [
    "# without roi rotate and with moran\n",
    "!python3 train.py --config=\"configs/config_new.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make: Entering directory '/home/dmivanov/end2end_OCR/utils/lanms'\n",
      "make: 'adaptor.so' is up to date.\n",
      "make: Leaving directory '/home/dmivanov/end2end_OCR/utils/lanms'\n",
      "100%|█████████████████████████████████████| 1000/1000 [00:00<00:00, 8504.23it/s]\n",
      "Trainable parameters: 648608\n",
      "SharedConv(\n",
      "  (backbone): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): None\n",
      "    (last_linear): Linear(in_features=2048, out_features=1000, bias=True)\n",
      "  )\n",
      "  (mergeLayers0): DummyLayer()\n",
      "  (mergeLayers1): HLayer(\n",
      "    (conv2dOne): Conv2d(3072, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (bnOne): BatchNorm2d(128, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
      "    (conv2dTwo): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bnTwo): BatchNorm2d(128, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (mergeLayers2): HLayer(\n",
      "    (conv2dOne): Conv2d(640, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (bnOne): BatchNorm2d(64, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
      "    (conv2dTwo): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bnTwo): BatchNorm2d(64, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (mergeLayers3): HLayer(\n",
      "    (conv2dOne): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (bnOne): BatchNorm2d(32, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
      "    (conv2dTwo): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bnTwo): BatchNorm2d(32, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (mergeLayers4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn5): BatchNorm2d(32, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
      ")\n",
      "Trainable parameters: 198\n",
      "Detector(\n",
      "  (scoreMap): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (geoMap): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (angleMap): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Trainable parameters: 648608\n",
      "SharedConv(\n",
      "  (backbone): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): None\n",
      "    (last_linear): Linear(in_features=2048, out_features=1000, bias=True)\n",
      "  )\n",
      "  (mergeLayers0): DummyLayer()\n",
      "  (mergeLayers1): HLayer(\n",
      "    (conv2dOne): Conv2d(3072, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (bnOne): BatchNorm2d(128, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
      "    (conv2dTwo): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bnTwo): BatchNorm2d(128, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (mergeLayers2): HLayer(\n",
      "    (conv2dOne): Conv2d(640, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (bnOne): BatchNorm2d(64, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
      "    (conv2dTwo): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bnTwo): BatchNorm2d(64, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (mergeLayers3): HLayer(\n",
      "    (conv2dOne): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (bnOne): BatchNorm2d(32, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
      "    (conv2dTwo): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bnTwo): BatchNorm2d(32, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (mergeLayers4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn5): BatchNorm2d(32, eps=1e-05, momentum=0.003, affine=True, track_running_stats=True)\n",
      ")\n",
      "Trainable parameters: 9969039\n",
      "Recognizer(\n",
      "  (crnn): CRNN(\n",
      "    (cnn): Sequential(\n",
      "      (conv0): Conv2d(32, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (batchnorm0): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu0): ReLU(inplace)\n",
      "      (conv1): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (batchnorm1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (HeightMaxPooling0): HeightMaxPool(\n",
      "        (pooling): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (conv2): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (batchnorm2): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv3): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (batchnorm3): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu3): ReLU(inplace)\n",
      "      (HeightMaxPooling1): HeightMaxPool(\n",
      "        (pooling): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (conv4): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (batchnorm4): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu4): ReLU(inplace)\n",
      "      (conv5): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (batchnorm5): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu5): ReLU(inplace)\n",
      "      (HeightMaxPooling2): HeightMaxPool(\n",
      "        (pooling): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "    )\n",
      "    (rnn): BidirectionalLSTM(\n",
      "      (rnn): LSTM(144, 1024, bidirectional=True)\n",
      "      (embedding): Linear(in_features=2048, out_features=63, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "ERROR\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is initialized.\n",
      "Memory Usage: \n",
      "    CUDA: 5  Allocated: 147.81103515625 MB Cached: 184.75 MB \n",
      "\n",
      "Loading checkpoint: /data/ivpaharitonov/saved_icdar_2017_2015/FOTS/model_best.pth.tar ...\n",
      "{'name': 'FOTS', 'cuda': True, 'gpus': [5], 'finetune': '/data/ivpaharitonov/saved_icdar_2017_2015/FOTS/model_best.pth.tar', 'data_loader': {'_dataset': 'synth800k', 'dataset': 'icdar2015', 'data_dir': '/data/ivpaharitonov/icdar2015/ICDAR2015/', '_data_dir': '/data/ivpaharitonov/', '__data_dir': '/Users/ivan_kharitonov/Google Drive/End2end_text_recognition_YSDA/datasets/SynthText/SynthText/', 'batch_size': 8, 'shuffle': True, 'workers': 0}, 'validation': {'validation_split': 0.1, 'shuffle': False}, 'lr_scheduler_type': 'ExponentialLR', 'lr_scheduler_freq': 10000, 'lr_scheduler': {'gamma': 0.94}, 'optimizer_type': 'Adam', 'optimizer': {'lr': 0.0001, 'weight_decay': 1e-05}, 'loss': 'FOTSLoss', 'metrics': ['fots_metric'], 'trainer': {'epochs': 100000, 'save_dir': '../saved/', 'save_freq': 1, 'verbosity': 2, 'monitor': 'loss', 'monitor_mode': 'min'}, 'arch': 'FOTSModel', 'rectifier': True, 'roi_rotate': True, 'need_grad_backbone': False, 'model': {'get_weights_for': ['conv_det', 'detector', 'conv_rec'], 'mode': 'united', '_mode': 'recognition', 'keys': 'alphabet_and_number', 'crnn': {'img_h': 16, 'hidden': 1024}}}\n",
      "/home/dmivanov/end2end_OCR/data_loader/datautils.py:234: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.linalg.norm(np.cross(p2 - p1, p1 - p3)) / np.linalg.norm(p2 - p1)\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2351: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2423: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "Train Epoch: 1 [0/904 (0%)] Loss: 41.979946 Detection Loss: 0.006977 Recognition Loss:41.972969\n",
      "Train Epoch: 1 [16/904 (2%)] Loss: 30.883144 Detection Loss: 0.014810 Recognition Loss:30.868336\n",
      "Train Epoch: 1 [32/904 (4%)] Loss: 35.292988 Detection Loss: 0.005452 Recognition Loss:35.287537\n",
      "Train Epoch: 1 [48/904 (5%)] Loss: 23.477798 Detection Loss: 0.012953 Recognition Loss:23.464846\n",
      "Train Epoch: 1 [64/904 (7%)] Loss: 21.615740 Detection Loss: 0.012489 Recognition Loss:21.603251\n",
      "Train Epoch: 1 [80/904 (9%)] Loss: 16.165543 Detection Loss: 0.018580 Recognition Loss:16.146963\n",
      "Train Epoch: 1 [96/904 (11%)] Loss: 10.561235 Detection Loss: 0.012329 Recognition Loss:10.548906\n",
      "Train Epoch: 1 [112/904 (12%)] Loss: 6.095727 Detection Loss: 0.006850 Recognition Loss:6.088878\n",
      "Train Epoch: 1 [128/904 (14%)] Loss: 5.072971 Detection Loss: 0.009373 Recognition Loss:5.063598\n",
      "Train Epoch: 1 [144/904 (16%)] Loss: 5.532929 Detection Loss: 0.008397 Recognition Loss:5.524532\n",
      "Train Epoch: 1 [160/904 (18%)] Loss: 6.472810 Detection Loss: 0.006301 Recognition Loss:6.466508\n",
      "Train Epoch: 1 [176/904 (19%)] Loss: 6.101496 Detection Loss: 0.009810 Recognition Loss:6.091685\n",
      "Train Epoch: 1 [192/904 (21%)] Loss: 5.848879 Detection Loss: 0.008799 Recognition Loss:5.840080\n",
      "Train Epoch: 1 [208/904 (23%)] Loss: 5.531629 Detection Loss: 0.013707 Recognition Loss:5.517922\n",
      "Train Epoch: 1 [224/904 (25%)] Loss: 5.186913 Detection Loss: 0.006550 Recognition Loss:5.180363\n",
      "Train Epoch: 1 [240/904 (27%)] Loss: 4.748189 Detection Loss: 0.008571 Recognition Loss:4.739618\n",
      "Train Epoch: 1 [256/904 (28%)] Loss: 4.558842 Detection Loss: 0.008888 Recognition Loss:4.549954\n",
      "Train Epoch: 1 [272/904 (30%)] Loss: 4.440071 Detection Loss: 0.004777 Recognition Loss:4.435294\n",
      "Train Epoch: 1 [288/904 (32%)] Loss: 4.301950 Detection Loss: 0.006338 Recognition Loss:4.295612\n",
      "Train Epoch: 1 [304/904 (34%)] Loss: 4.037776 Detection Loss: 0.011794 Recognition Loss:4.025981\n",
      "Train Epoch: 1 [320/904 (35%)] Loss: 4.101723 Detection Loss: 0.008545 Recognition Loss:4.093177\n",
      "Train Epoch: 1 [336/904 (37%)] Loss: 4.522799 Detection Loss: 0.010517 Recognition Loss:4.512282\n",
      "Train Epoch: 1 [352/904 (39%)] Loss: 4.168920 Detection Loss: 0.014957 Recognition Loss:4.153963\n",
      "Train Epoch: 1 [368/904 (41%)] Loss: 4.295424 Detection Loss: 0.006255 Recognition Loss:4.289168\n",
      "Train Epoch: 1 [384/904 (42%)] Loss: 4.278836 Detection Loss: 0.005475 Recognition Loss:4.273360\n",
      "Train Epoch: 1 [400/904 (44%)] Loss: 4.506143 Detection Loss: 0.006183 Recognition Loss:4.499960\n",
      "Train Epoch: 1 [416/904 (46%)] Loss: 3.942186 Detection Loss: 0.009396 Recognition Loss:3.932790\n",
      "Train Epoch: 1 [432/904 (48%)] Loss: 4.102736 Detection Loss: 0.012534 Recognition Loss:4.090202\n",
      "Train Epoch: 1 [448/904 (50%)] Loss: 3.933421 Detection Loss: 0.008568 Recognition Loss:3.924853\n",
      "Train Epoch: 1 [464/904 (51%)] Loss: 4.244040 Detection Loss: 0.009952 Recognition Loss:4.234088\n",
      "Train Epoch: 1 [480/904 (53%)] Loss: 4.258552 Detection Loss: 0.013436 Recognition Loss:4.245116\n",
      "Train Epoch: 1 [496/904 (55%)] Loss: 3.982453 Detection Loss: 0.005651 Recognition Loss:3.976802\n",
      "Train Epoch: 1 [512/904 (57%)] Loss: 4.061022 Detection Loss: 0.021916 Recognition Loss:4.039106\n",
      "Train Epoch: 1 [528/904 (58%)] Loss: 3.960662 Detection Loss: 0.008480 Recognition Loss:3.952182\n",
      "Train Epoch: 1 [544/904 (60%)] Loss: 4.173867 Detection Loss: 0.009608 Recognition Loss:4.164259\n",
      "Train Epoch: 1 [560/904 (62%)] Loss: 4.099102 Detection Loss: 0.009013 Recognition Loss:4.090090\n",
      "Train Epoch: 1 [576/904 (64%)] Loss: 3.882113 Detection Loss: 0.008454 Recognition Loss:3.873659\n",
      "Train Epoch: 1 [592/904 (65%)] Loss: 4.109594 Detection Loss: 0.003978 Recognition Loss:4.105616\n",
      "Train Epoch: 1 [608/904 (67%)] Loss: 3.953631 Detection Loss: 0.008354 Recognition Loss:3.945277\n",
      "Train Epoch: 1 [624/904 (69%)] Loss: 4.173047 Detection Loss: 0.011412 Recognition Loss:4.161635\n",
      "Train Epoch: 1 [640/904 (71%)] Loss: 3.702605 Detection Loss: 0.006900 Recognition Loss:3.695706\n",
      "Train Epoch: 1 [656/904 (73%)] Loss: 4.032569 Detection Loss: 0.010255 Recognition Loss:4.022314\n",
      "Train Epoch: 1 [672/904 (74%)] Loss: 3.908563 Detection Loss: 0.010332 Recognition Loss:3.898231\n",
      "Train Epoch: 1 [688/904 (76%)] Loss: 3.940275 Detection Loss: 0.009233 Recognition Loss:3.931042\n",
      "Train Epoch: 1 [704/904 (78%)] Loss: 3.709780 Detection Loss: 0.006840 Recognition Loss:3.702940\n",
      "Train Epoch: 1 [720/904 (80%)] Loss: 4.059417 Detection Loss: 0.006286 Recognition Loss:4.053131\n",
      "Train Epoch: 1 [736/904 (81%)] Loss: 3.829345 Detection Loss: 0.010917 Recognition Loss:3.818429\n",
      "Train Epoch: 1 [752/904 (83%)] Loss: 3.972030 Detection Loss: 0.006028 Recognition Loss:3.966002\n",
      "Train Epoch: 1 [768/904 (85%)] Loss: 4.446576 Detection Loss: 0.013021 Recognition Loss:4.433555\n",
      "Train Epoch: 1 [784/904 (87%)] Loss: 4.086424 Detection Loss: 0.006023 Recognition Loss:4.080401\n",
      "Train Epoch: 1 [800/904 (88%)] Loss: 3.946672 Detection Loss: 0.008499 Recognition Loss:3.938173\n",
      "Train Epoch: 1 [816/904 (90%)] Loss: 3.987751 Detection Loss: 0.007834 Recognition Loss:3.979917\n",
      "Train Epoch: 1 [832/904 (92%)] Loss: 4.031742 Detection Loss: 0.008797 Recognition Loss:4.022944\n",
      "Train Epoch: 1 [848/904 (94%)] Loss: 3.946236 Detection Loss: 0.010663 Recognition Loss:3.935573\n",
      "Train Epoch: 1 [864/904 (96%)] Loss: 3.967103 Detection Loss: 0.011664 Recognition Loss:3.955440\n",
      "Train Epoch: 1 [880/904 (97%)] Loss: 4.015834 Detection Loss: 0.007322 Recognition Loss:4.008512\n",
      "Train Epoch: 1 [896/904 (99%)] Loss: 3.868135 Detection Loss: 0.007193 Recognition Loss:3.860942\n",
      "Start validate\n",
      "    epoch          : 1\n",
      "    loss           : 6.83821400287932\n",
      "    det_loss       : 0.00951843576472813\n",
      "    rec_loss       : 6.8286955778577685\n",
      "    precious       : 0.0\n",
      "    recall         : 0.0\n",
      "    hmean          : 0.0\n",
      "    val_loss       : 4.0170593890003286\n",
      "    val_det_loss   : 0.009881009061176043\n",
      "    val_rec_loss   : 4.007178379939153\n",
      "    val_precious   : 0.0\n",
      "    val_recall     : 0.0\n",
      "    val_hmean      : 0.0\n",
      "Saving current best: model_best.pth.tar ...\n",
      "Saving checkpoint: ../saved/FOTS/checkpoint-epoch001-loss-6.8382.pth.tar ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [0/904 (0%)] Loss: 4.002858 Detection Loss: 0.006272 Recognition Loss:3.996585\n",
      "Train Epoch: 2 [16/904 (2%)] Loss: 3.878651 Detection Loss: 0.018652 Recognition Loss:3.859999\n",
      "Train Epoch: 2 [32/904 (4%)] Loss: 3.875656 Detection Loss: 0.005654 Recognition Loss:3.870003\n",
      "Train Epoch: 2 [48/904 (5%)] Loss: 3.990477 Detection Loss: 0.007837 Recognition Loss:3.982640\n",
      "Train Epoch: 2 [64/904 (7%)] Loss: 3.810835 Detection Loss: 0.004690 Recognition Loss:3.806145\n",
      "Train Epoch: 2 [80/904 (9%)] Loss: 4.048354 Detection Loss: 0.012030 Recognition Loss:4.036324\n",
      "Train Epoch: 2 [96/904 (11%)] Loss: 3.628294 Detection Loss: 0.016286 Recognition Loss:3.612008\n",
      "Train Epoch: 2 [112/904 (12%)] Loss: 3.843339 Detection Loss: 0.030711 Recognition Loss:3.812627\n",
      "Train Epoch: 2 [128/904 (14%)] Loss: 3.580286 Detection Loss: 0.005654 Recognition Loss:3.574632\n",
      "Train Epoch: 2 [144/904 (16%)] Loss: 3.718156 Detection Loss: 0.005835 Recognition Loss:3.712321\n",
      "Train Epoch: 2 [160/904 (18%)] Loss: 3.886250 Detection Loss: 0.009415 Recognition Loss:3.876834\n",
      "Train Epoch: 2 [176/904 (19%)] Loss: 4.056980 Detection Loss: 0.021956 Recognition Loss:4.035024\n",
      "Train Epoch: 2 [192/904 (21%)] Loss: 3.945829 Detection Loss: 0.006129 Recognition Loss:3.939701\n",
      "Train Epoch: 2 [208/904 (23%)] Loss: 3.867204 Detection Loss: 0.012745 Recognition Loss:3.854459\n",
      "Train Epoch: 2 [224/904 (25%)] Loss: 4.031800 Detection Loss: 0.007404 Recognition Loss:4.024397\n",
      "Train Epoch: 2 [240/904 (27%)] Loss: 3.982329 Detection Loss: 0.009084 Recognition Loss:3.973245\n",
      "Train Epoch: 2 [256/904 (28%)] Loss: 3.975179 Detection Loss: 0.007867 Recognition Loss:3.967313\n",
      "Train Epoch: 2 [272/904 (30%)] Loss: 4.016873 Detection Loss: 0.011214 Recognition Loss:4.005659\n",
      "Train Epoch: 2 [288/904 (32%)] Loss: 3.920948 Detection Loss: 0.011473 Recognition Loss:3.909475\n",
      "Train Epoch: 2 [304/904 (34%)] Loss: 4.032549 Detection Loss: 0.008207 Recognition Loss:4.024342\n",
      "Train Epoch: 2 [320/904 (35%)] Loss: 3.974528 Detection Loss: 0.010340 Recognition Loss:3.964188\n",
      "Train Epoch: 2 [336/904 (37%)] Loss: 3.868379 Detection Loss: 0.008618 Recognition Loss:3.859762\n",
      "Train Epoch: 2 [352/904 (39%)] Loss: 4.113908 Detection Loss: 0.006435 Recognition Loss:4.107472\n",
      "Train Epoch: 2 [368/904 (41%)] Loss: 3.762492 Detection Loss: 0.017673 Recognition Loss:3.744820\n",
      "Train Epoch: 2 [384/904 (42%)] Loss: 3.983623 Detection Loss: 0.010053 Recognition Loss:3.973571\n",
      "Train Epoch: 2 [400/904 (44%)] Loss: 3.912621 Detection Loss: 0.009079 Recognition Loss:3.903542\n",
      "Train Epoch: 2 [416/904 (46%)] Loss: 3.716123 Detection Loss: 0.010135 Recognition Loss:3.705988\n",
      "Train Epoch: 2 [432/904 (48%)] Loss: 3.953461 Detection Loss: 0.007265 Recognition Loss:3.946196\n",
      "Train Epoch: 2 [448/904 (50%)] Loss: 3.856700 Detection Loss: 0.011505 Recognition Loss:3.845195\n",
      "Train Epoch: 2 [464/904 (51%)] Loss: 3.708925 Detection Loss: 0.007584 Recognition Loss:3.701341\n",
      "Train Epoch: 2 [480/904 (53%)] Loss: 4.232793 Detection Loss: 0.010106 Recognition Loss:4.222687\n",
      "Train Epoch: 2 [496/904 (55%)] Loss: 3.796905 Detection Loss: 0.015243 Recognition Loss:3.781662\n",
      "Train Epoch: 2 [512/904 (57%)] Loss: 3.678420 Detection Loss: 0.011175 Recognition Loss:3.667245\n",
      "Train Epoch: 2 [528/904 (58%)] Loss: 3.884640 Detection Loss: 0.007134 Recognition Loss:3.877506\n",
      "Train Epoch: 2 [544/904 (60%)] Loss: 3.719052 Detection Loss: 0.008540 Recognition Loss:3.710511\n",
      "Train Epoch: 2 [560/904 (62%)] Loss: 4.157801 Detection Loss: 0.009630 Recognition Loss:4.148171\n",
      "Train Epoch: 2 [576/904 (64%)] Loss: 4.057075 Detection Loss: 0.018012 Recognition Loss:4.039063\n",
      "Train Epoch: 2 [592/904 (65%)] Loss: 3.948265 Detection Loss: 0.009051 Recognition Loss:3.939214\n",
      "Train Epoch: 2 [608/904 (67%)] Loss: 3.847924 Detection Loss: 0.005931 Recognition Loss:3.841993\n",
      "Train Epoch: 2 [624/904 (69%)] Loss: 3.856390 Detection Loss: 0.009265 Recognition Loss:3.847125\n",
      "Train Epoch: 2 [640/904 (71%)] Loss: 4.044434 Detection Loss: 0.005611 Recognition Loss:4.038823\n",
      "Train Epoch: 2 [656/904 (73%)] Loss: 4.192078 Detection Loss: 0.006587 Recognition Loss:4.185491\n",
      "Train Epoch: 2 [672/904 (74%)] Loss: 3.621495 Detection Loss: 0.008648 Recognition Loss:3.612847\n",
      "Train Epoch: 2 [688/904 (76%)] Loss: 3.823428 Detection Loss: 0.004753 Recognition Loss:3.818676\n",
      "Train Epoch: 2 [704/904 (78%)] Loss: 3.975009 Detection Loss: 0.008111 Recognition Loss:3.966898\n",
      "Train Epoch: 2 [720/904 (80%)] Loss: 3.891947 Detection Loss: 0.013834 Recognition Loss:3.878113\n",
      "Train Epoch: 2 [736/904 (81%)] Loss: 3.763989 Detection Loss: 0.006063 Recognition Loss:3.757926\n",
      "Train Epoch: 2 [752/904 (83%)] Loss: 3.938014 Detection Loss: 0.005391 Recognition Loss:3.932623\n",
      "Train Epoch: 2 [768/904 (85%)] Loss: 4.021502 Detection Loss: 0.009523 Recognition Loss:4.011979\n",
      "Train Epoch: 2 [784/904 (87%)] Loss: 4.466104 Detection Loss: 0.006165 Recognition Loss:4.459939\n",
      "Train Epoch: 2 [800/904 (88%)] Loss: 3.861371 Detection Loss: 0.007182 Recognition Loss:3.854189\n",
      "Train Epoch: 2 [816/904 (90%)] Loss: 3.970259 Detection Loss: 0.008807 Recognition Loss:3.961452\n",
      "Train Epoch: 2 [832/904 (92%)] Loss: 3.807875 Detection Loss: 0.005215 Recognition Loss:3.802660\n",
      "Train Epoch: 2 [848/904 (94%)] Loss: 3.750262 Detection Loss: 0.015935 Recognition Loss:3.734327\n",
      "Train Epoch: 2 [864/904 (96%)] Loss: 4.156945 Detection Loss: 0.014210 Recognition Loss:4.142735\n",
      "Train Epoch: 2 [880/904 (97%)] Loss: 4.268703 Detection Loss: 0.006733 Recognition Loss:4.261970\n",
      "Train Epoch: 2 [896/904 (99%)] Loss: 3.930426 Detection Loss: 0.006008 Recognition Loss:3.924417\n",
      "Start validate\n",
      "    epoch          : 2\n",
      "    loss           : 3.914616321040466\n",
      "    det_loss       : 0.009471248794116278\n",
      "    rec_loss       : 3.9051450691391936\n",
      "    precious       : 0.0\n",
      "    recall         : 0.0\n",
      "    hmean          : 0.0\n",
      "    val_loss       : 3.9054438107861924\n",
      "    val_det_loss   : 0.009707153130036134\n",
      "    val_rec_loss   : 3.895736657656156\n",
      "    val_precious   : 0.0\n",
      "    val_recall     : 0.0\n",
      "    val_hmean      : 0.0\n",
      "Saving current best: model_best.pth.tar ...\n",
      "Saving checkpoint: ../saved/FOTS/checkpoint-epoch002-loss-3.9146.pth.tar ...\n",
      "Train Epoch: 3 [0/904 (0%)] Loss: 3.498348 Detection Loss: 0.007975 Recognition Loss:3.490373\n",
      "Train Epoch: 3 [16/904 (2%)] Loss: 3.846587 Detection Loss: 0.014184 Recognition Loss:3.832403\n",
      "Train Epoch: 3 [32/904 (4%)] Loss: 3.741116 Detection Loss: 0.011680 Recognition Loss:3.729436\n",
      "Train Epoch: 3 [48/904 (5%)] Loss: 3.894245 Detection Loss: 0.010862 Recognition Loss:3.883383\n",
      "Train Epoch: 3 [64/904 (7%)] Loss: 3.917992 Detection Loss: 0.007667 Recognition Loss:3.910325\n",
      "Train Epoch: 3 [80/904 (9%)] Loss: 4.026341 Detection Loss: 0.007909 Recognition Loss:4.018432\n",
      "Train Epoch: 3 [96/904 (11%)] Loss: 3.697022 Detection Loss: 0.009736 Recognition Loss:3.687286\n",
      "Train Epoch: 3 [112/904 (12%)] Loss: 3.974896 Detection Loss: 0.008180 Recognition Loss:3.966717\n",
      "Train Epoch: 3 [128/904 (14%)] Loss: 4.134138 Detection Loss: 0.010155 Recognition Loss:4.123983\n",
      "Train Epoch: 3 [144/904 (16%)] Loss: 3.967813 Detection Loss: 0.012943 Recognition Loss:3.954870\n",
      "Train Epoch: 3 [160/904 (18%)] Loss: 3.986677 Detection Loss: 0.004518 Recognition Loss:3.982159\n",
      "Train Epoch: 3 [176/904 (19%)] Loss: 3.984303 Detection Loss: 0.010466 Recognition Loss:3.973836\n",
      "Train Epoch: 3 [192/904 (21%)] Loss: 3.899490 Detection Loss: 0.008951 Recognition Loss:3.890539\n",
      "Train Epoch: 3 [208/904 (23%)] Loss: 3.902302 Detection Loss: 0.010237 Recognition Loss:3.892066\n",
      "Train Epoch: 3 [224/904 (25%)] Loss: 3.982202 Detection Loss: 0.005679 Recognition Loss:3.976522\n",
      "Train Epoch: 3 [240/904 (27%)] Loss: 3.628008 Detection Loss: 0.008412 Recognition Loss:3.619596\n",
      "Train Epoch: 3 [256/904 (28%)] Loss: 3.813086 Detection Loss: 0.009912 Recognition Loss:3.803174\n",
      "Train Epoch: 3 [272/904 (30%)] Loss: 3.960826 Detection Loss: 0.009233 Recognition Loss:3.951593\n",
      "Train Epoch: 3 [288/904 (32%)] Loss: 3.730383 Detection Loss: 0.008336 Recognition Loss:3.722047\n",
      "Train Epoch: 3 [304/904 (34%)] Loss: 4.005752 Detection Loss: 0.014270 Recognition Loss:3.991482\n",
      "Train Epoch: 3 [320/904 (35%)] Loss: 3.999354 Detection Loss: 0.014331 Recognition Loss:3.985023\n",
      "Train Epoch: 3 [336/904 (37%)] Loss: 4.026204 Detection Loss: 0.008005 Recognition Loss:4.018198\n",
      "Train Epoch: 3 [352/904 (39%)] Loss: 3.862883 Detection Loss: 0.009729 Recognition Loss:3.853154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [368/904 (41%)] Loss: 4.396116 Detection Loss: 0.008022 Recognition Loss:4.388094\n",
      "Train Epoch: 3 [384/904 (42%)] Loss: 4.185204 Detection Loss: 0.004789 Recognition Loss:4.180415\n",
      "Train Epoch: 3 [400/904 (44%)] Loss: 3.831627 Detection Loss: 0.010363 Recognition Loss:3.821264\n",
      "Train Epoch: 3 [416/904 (46%)] Loss: 4.059593 Detection Loss: 0.008407 Recognition Loss:4.051186\n",
      "Train Epoch: 3 [432/904 (48%)] Loss: 3.951011 Detection Loss: 0.006641 Recognition Loss:3.944371\n",
      "Train Epoch: 3 [448/904 (50%)] Loss: 3.971899 Detection Loss: 0.005687 Recognition Loss:3.966212\n",
      "Train Epoch: 3 [464/904 (51%)] Loss: 3.992695 Detection Loss: 0.005699 Recognition Loss:3.986995\n",
      "Train Epoch: 3 [480/904 (53%)] Loss: 3.887434 Detection Loss: 0.006532 Recognition Loss:3.880902\n",
      "Train Epoch: 3 [496/904 (55%)] Loss: 3.966776 Detection Loss: 0.005604 Recognition Loss:3.961172\n",
      "Train Epoch: 3 [512/904 (57%)] Loss: 4.049926 Detection Loss: 0.011015 Recognition Loss:4.038911\n",
      "Train Epoch: 3 [528/904 (58%)] Loss: 3.824165 Detection Loss: 0.013924 Recognition Loss:3.810241\n",
      "Train Epoch: 3 [544/904 (60%)] Loss: 3.988084 Detection Loss: 0.006067 Recognition Loss:3.982017\n",
      "Train Epoch: 3 [560/904 (62%)] Loss: 3.789295 Detection Loss: 0.007816 Recognition Loss:3.781479\n",
      "Train Epoch: 3 [576/904 (64%)] Loss: 4.063776 Detection Loss: 0.006417 Recognition Loss:4.057360\n",
      "Train Epoch: 3 [592/904 (65%)] Loss: 4.010093 Detection Loss: 0.005936 Recognition Loss:4.004157\n",
      "Train Epoch: 3 [608/904 (67%)] Loss: 3.733622 Detection Loss: 0.006935 Recognition Loss:3.726687\n",
      "Train Epoch: 3 [624/904 (69%)] Loss: 4.090401 Detection Loss: 0.011679 Recognition Loss:4.078722\n",
      "Train Epoch: 3 [640/904 (71%)] Loss: 3.764959 Detection Loss: 0.005324 Recognition Loss:3.759635\n",
      "Train Epoch: 3 [656/904 (73%)] Loss: 4.021706 Detection Loss: 0.005209 Recognition Loss:4.016497\n",
      "Train Epoch: 3 [672/904 (74%)] Loss: 4.026402 Detection Loss: 0.006907 Recognition Loss:4.019495\n",
      "Train Epoch: 3 [688/904 (76%)] Loss: 3.871391 Detection Loss: 0.006695 Recognition Loss:3.864695\n",
      "Train Epoch: 3 [704/904 (78%)] Loss: 3.876799 Detection Loss: 0.019211 Recognition Loss:3.857588\n",
      "Train Epoch: 3 [720/904 (80%)] Loss: 3.965882 Detection Loss: 0.006718 Recognition Loss:3.959165\n",
      "Train Epoch: 3 [736/904 (81%)] Loss: 3.832320 Detection Loss: 0.005667 Recognition Loss:3.826653\n",
      "Train Epoch: 3 [752/904 (83%)] Loss: 4.141559 Detection Loss: 0.012353 Recognition Loss:4.129206\n",
      "Train Epoch: 3 [768/904 (85%)] Loss: 3.905979 Detection Loss: 0.008676 Recognition Loss:3.897303\n",
      "Train Epoch: 3 [784/904 (87%)] Loss: 4.279171 Detection Loss: 0.007944 Recognition Loss:4.271227\n",
      "Train Epoch: 3 [800/904 (88%)] Loss: 3.825236 Detection Loss: 0.006596 Recognition Loss:3.818640\n",
      "Train Epoch: 3 [816/904 (90%)] Loss: 3.807582 Detection Loss: 0.009937 Recognition Loss:3.797645\n",
      "Train Epoch: 3 [832/904 (92%)] Loss: 3.684584 Detection Loss: 0.007940 Recognition Loss:3.676644\n",
      "Train Epoch: 3 [848/904 (94%)] Loss: 4.174351 Detection Loss: 0.006961 Recognition Loss:4.167389\n",
      "Train Epoch: 3 [864/904 (96%)] Loss: 3.711535 Detection Loss: 0.008238 Recognition Loss:3.703297\n",
      "Train Epoch: 3 [880/904 (97%)] Loss: 3.821860 Detection Loss: 0.007529 Recognition Loss:3.814330\n",
      "Train Epoch: 3 [896/904 (99%)] Loss: 3.772013 Detection Loss: 0.004676 Recognition Loss:3.767337\n",
      "Start validate\n",
      "    epoch          : 3\n",
      "    loss           : 3.919930238639359\n",
      "    det_loss       : 0.009725965003161568\n",
      "    rec_loss       : 3.910204275519447\n",
      "    precious       : 0.0\n",
      "    recall         : 0.0\n",
      "    hmean          : 0.0\n",
      "    val_loss       : 3.960139669334659\n",
      "    val_det_loss   : 0.009638374098218404\n",
      "    val_rec_loss   : 3.9505012952364407\n",
      "    val_precious   : 0.0\n",
      "    val_recall     : 0.0\n",
      "    val_hmean      : 0.0\n",
      "Saving checkpoint: ../saved/FOTS/checkpoint-epoch003-loss-3.9199.pth.tar ...\n",
      "Train Epoch: 4 [0/904 (0%)] Loss: 3.779505 Detection Loss: 0.007460 Recognition Loss:3.772046\n",
      "Train Epoch: 4 [16/904 (2%)] Loss: 3.900175 Detection Loss: 0.013277 Recognition Loss:3.886899\n",
      "Train Epoch: 4 [32/904 (4%)] Loss: 3.996968 Detection Loss: 0.005639 Recognition Loss:3.991329\n",
      "Train Epoch: 4 [48/904 (5%)] Loss: 3.872544 Detection Loss: 0.010922 Recognition Loss:3.861622\n",
      "Train Epoch: 4 [64/904 (7%)] Loss: 3.777405 Detection Loss: 0.005313 Recognition Loss:3.772092\n",
      "Train Epoch: 4 [80/904 (9%)] Loss: 3.817093 Detection Loss: 0.007831 Recognition Loss:3.809262\n",
      "Train Epoch: 4 [96/904 (11%)] Loss: 4.035313 Detection Loss: 0.011320 Recognition Loss:4.023993\n",
      "Train Epoch: 4 [112/904 (12%)] Loss: 3.869073 Detection Loss: 0.007822 Recognition Loss:3.861251\n",
      "Train Epoch: 4 [128/904 (14%)] Loss: 3.782599 Detection Loss: 0.013091 Recognition Loss:3.769507\n",
      "Train Epoch: 4 [144/904 (16%)] Loss: 3.980832 Detection Loss: 0.007705 Recognition Loss:3.973127\n",
      "Train Epoch: 4 [160/904 (18%)] Loss: 3.965597 Detection Loss: 0.010100 Recognition Loss:3.955497\n",
      "Train Epoch: 4 [176/904 (19%)] Loss: 4.036940 Detection Loss: 0.008295 Recognition Loss:4.028645\n",
      "Train Epoch: 4 [192/904 (21%)] Loss: 4.175254 Detection Loss: 0.009242 Recognition Loss:4.166012\n",
      "Train Epoch: 4 [208/904 (23%)] Loss: 3.938462 Detection Loss: 0.005186 Recognition Loss:3.933275\n",
      "Train Epoch: 4 [224/904 (25%)] Loss: 4.131275 Detection Loss: 0.014937 Recognition Loss:4.116339\n",
      "Train Epoch: 4 [240/904 (27%)] Loss: 3.746917 Detection Loss: 0.013374 Recognition Loss:3.733543\n",
      "Train Epoch: 4 [256/904 (28%)] Loss: 4.183728 Detection Loss: 0.007167 Recognition Loss:4.176561\n",
      "Train Epoch: 4 [272/904 (30%)] Loss: 3.801662 Detection Loss: 0.005626 Recognition Loss:3.796036\n",
      "Train Epoch: 4 [288/904 (32%)] Loss: 3.959485 Detection Loss: 0.018674 Recognition Loss:3.940810\n",
      "Train Epoch: 4 [304/904 (34%)] Loss: 3.949833 Detection Loss: 0.009225 Recognition Loss:3.940608\n",
      "Train Epoch: 4 [320/904 (35%)] Loss: 3.761918 Detection Loss: 0.007867 Recognition Loss:3.754051\n",
      "Train Epoch: 4 [336/904 (37%)] Loss: 3.994476 Detection Loss: 0.010931 Recognition Loss:3.983545\n",
      "Train Epoch: 4 [352/904 (39%)] Loss: 4.040223 Detection Loss: 0.008216 Recognition Loss:4.032006\n",
      "Train Epoch: 4 [368/904 (41%)] Loss: 4.002947 Detection Loss: 0.005947 Recognition Loss:3.997000\n",
      "Train Epoch: 4 [384/904 (42%)] Loss: 3.746551 Detection Loss: 0.026952 Recognition Loss:3.719599\n",
      "Train Epoch: 4 [400/904 (44%)] Loss: 4.015068 Detection Loss: 0.007512 Recognition Loss:4.007556\n",
      "Train Epoch: 4 [416/904 (46%)] Loss: 4.181467 Detection Loss: 0.005482 Recognition Loss:4.175985\n",
      "Train Epoch: 4 [432/904 (48%)] Loss: 4.173130 Detection Loss: 0.026615 Recognition Loss:4.146514\n",
      "Train Epoch: 4 [448/904 (50%)] Loss: 3.968020 Detection Loss: 0.010595 Recognition Loss:3.957425\n",
      "Train Epoch: 4 [464/904 (51%)] Loss: 4.071751 Detection Loss: 0.005651 Recognition Loss:4.066101\n",
      "Train Epoch: 4 [480/904 (53%)] Loss: 3.883882 Detection Loss: 0.010363 Recognition Loss:3.873519\n",
      "Train Epoch: 4 [496/904 (55%)] Loss: 3.856054 Detection Loss: 0.006560 Recognition Loss:3.849494\n",
      "Train Epoch: 4 [512/904 (57%)] Loss: 3.951448 Detection Loss: 0.009822 Recognition Loss:3.941626\n",
      "Train Epoch: 4 [528/904 (58%)] Loss: 4.269194 Detection Loss: 0.014991 Recognition Loss:4.254203\n",
      "Train Epoch: 4 [544/904 (60%)] Loss: 4.015442 Detection Loss: 0.013156 Recognition Loss:4.002286\n",
      "Train Epoch: 4 [560/904 (62%)] Loss: 3.873930 Detection Loss: 0.007816 Recognition Loss:3.866114\n",
      "Train Epoch: 4 [576/904 (64%)] Loss: 3.888332 Detection Loss: 0.007298 Recognition Loss:3.881034\n",
      "Train Epoch: 4 [592/904 (65%)] Loss: 3.869199 Detection Loss: 0.007005 Recognition Loss:3.862194\n",
      "Train Epoch: 4 [608/904 (67%)] Loss: 4.037561 Detection Loss: 0.007133 Recognition Loss:4.030428\n",
      "Train Epoch: 4 [624/904 (69%)] Loss: 4.123328 Detection Loss: 0.012893 Recognition Loss:4.110434\n",
      "Train Epoch: 4 [640/904 (71%)] Loss: 3.864151 Detection Loss: 0.007684 Recognition Loss:3.856467\n",
      "Train Epoch: 4 [656/904 (73%)] Loss: 3.835846 Detection Loss: 0.006521 Recognition Loss:3.829325\n",
      "Train Epoch: 4 [672/904 (74%)] Loss: 3.698384 Detection Loss: 0.007703 Recognition Loss:3.690681\n",
      "Train Epoch: 4 [688/904 (76%)] Loss: 3.776080 Detection Loss: 0.007339 Recognition Loss:3.768741\n",
      "Train Epoch: 4 [704/904 (78%)] Loss: 4.103506 Detection Loss: 0.015675 Recognition Loss:4.087831\n",
      "Train Epoch: 4 [720/904 (80%)] Loss: 3.941891 Detection Loss: 0.006426 Recognition Loss:3.935465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [736/904 (81%)] Loss: 4.142827 Detection Loss: 0.008693 Recognition Loss:4.134134\n",
      "Train Epoch: 4 [752/904 (83%)] Loss: 3.859742 Detection Loss: 0.006930 Recognition Loss:3.852812\n",
      "Train Epoch: 4 [768/904 (85%)] Loss: 3.778187 Detection Loss: 0.008587 Recognition Loss:3.769601\n",
      "Train Epoch: 4 [784/904 (87%)] Loss: 4.065303 Detection Loss: 0.008665 Recognition Loss:4.056639\n",
      "Train Epoch: 4 [800/904 (88%)] Loss: 3.744704 Detection Loss: 0.013603 Recognition Loss:3.731100\n",
      "Train Epoch: 4 [816/904 (90%)] Loss: 3.814341 Detection Loss: 0.020291 Recognition Loss:3.794050\n",
      "Train Epoch: 4 [832/904 (92%)] Loss: 4.046963 Detection Loss: 0.022656 Recognition Loss:4.024307\n",
      "Train Epoch: 4 [848/904 (94%)] Loss: 3.908935 Detection Loss: 0.005269 Recognition Loss:3.903666\n",
      "Train Epoch: 4 [864/904 (96%)] Loss: 3.825674 Detection Loss: 0.007805 Recognition Loss:3.817868\n",
      "Train Epoch: 4 [880/904 (97%)] Loss: 3.755018 Detection Loss: 0.016732 Recognition Loss:3.738285\n",
      "Train Epoch: 4 [896/904 (99%)] Loss: 3.780340 Detection Loss: 0.005837 Recognition Loss:3.774503\n",
      "Start validate\n",
      "    epoch          : 4\n",
      "    loss           : 3.9322760843597684\n",
      "    det_loss       : 0.010118303371313135\n",
      "    rec_loss       : 3.9221577876437026\n",
      "    precious       : 0.0\n",
      "    recall         : 0.0\n",
      "    hmean          : 0.0\n",
      "    val_loss       : 3.9148621751497\n",
      "    val_det_loss   : 0.010699199691701394\n",
      "    val_rec_loss   : 3.9041629754579983\n",
      "    val_precious   : 0.0\n",
      "    val_recall     : 0.0\n",
      "    val_hmean      : 0.0\n",
      "Saving checkpoint: ../saved/FOTS/checkpoint-epoch004-loss-3.9323.pth.tar ...\n",
      "Train Epoch: 5 [0/904 (0%)] Loss: 3.958227 Detection Loss: 0.004874 Recognition Loss:3.953352\n",
      "Train Epoch: 5 [16/904 (2%)] Loss: 3.981759 Detection Loss: 0.006145 Recognition Loss:3.975614\n",
      "Train Epoch: 5 [32/904 (4%)] Loss: 3.831413 Detection Loss: 0.008278 Recognition Loss:3.823135\n",
      "Train Epoch: 5 [48/904 (5%)] Loss: 3.670853 Detection Loss: 0.011391 Recognition Loss:3.659462\n",
      "Train Epoch: 5 [64/904 (7%)] Loss: 3.777850 Detection Loss: 0.008908 Recognition Loss:3.768942\n",
      "Train Epoch: 5 [80/904 (9%)] Loss: 3.938706 Detection Loss: 0.009829 Recognition Loss:3.928878\n",
      "Train Epoch: 5 [96/904 (11%)] Loss: 3.759146 Detection Loss: 0.005938 Recognition Loss:3.753208\n",
      "Train Epoch: 5 [112/904 (12%)] Loss: 3.873123 Detection Loss: 0.006008 Recognition Loss:3.867115\n",
      "Train Epoch: 5 [128/904 (14%)] Loss: 4.049157 Detection Loss: 0.012128 Recognition Loss:4.037028\n",
      "Train Epoch: 5 [144/904 (16%)] Loss: 3.634146 Detection Loss: 0.023576 Recognition Loss:3.610570\n",
      "Train Epoch: 5 [160/904 (18%)] Loss: 3.852547 Detection Loss: 0.007846 Recognition Loss:3.844701\n",
      "Train Epoch: 5 [176/904 (19%)] Loss: 3.735260 Detection Loss: 0.006719 Recognition Loss:3.728541\n",
      "Train Epoch: 5 [192/904 (21%)] Loss: 4.275926 Detection Loss: 0.014279 Recognition Loss:4.261647\n",
      "Train Epoch: 5 [208/904 (23%)] Loss: 4.218209 Detection Loss: 0.010124 Recognition Loss:4.208086\n",
      "Train Epoch: 5 [224/904 (25%)] Loss: 3.807873 Detection Loss: 0.008980 Recognition Loss:3.798893\n",
      "Train Epoch: 5 [240/904 (27%)] Loss: 4.003631 Detection Loss: 0.016425 Recognition Loss:3.987206\n",
      "Train Epoch: 5 [256/904 (28%)] Loss: 3.514279 Detection Loss: 0.011180 Recognition Loss:3.503099\n",
      "Train Epoch: 5 [272/904 (30%)] Loss: 3.901568 Detection Loss: 0.005756 Recognition Loss:3.895813\n",
      "Train Epoch: 5 [288/904 (32%)] Loss: 3.868965 Detection Loss: 0.009403 Recognition Loss:3.859562\n",
      "Train Epoch: 5 [304/904 (34%)] Loss: 4.252463 Detection Loss: 0.012497 Recognition Loss:4.239966\n",
      "Train Epoch: 5 [320/904 (35%)] Loss: 4.140973 Detection Loss: 0.009542 Recognition Loss:4.131432\n",
      "Train Epoch: 5 [336/904 (37%)] Loss: 3.988935 Detection Loss: 0.010358 Recognition Loss:3.978577\n",
      "Train Epoch: 5 [352/904 (39%)] Loss: 3.931294 Detection Loss: 0.006467 Recognition Loss:3.924828\n",
      "Train Epoch: 5 [368/904 (41%)] Loss: 4.541260 Detection Loss: 0.006442 Recognition Loss:4.534818\n",
      "Train Epoch: 5 [384/904 (42%)] Loss: 3.657335 Detection Loss: 0.008481 Recognition Loss:3.648854\n",
      "Train Epoch: 5 [400/904 (44%)] Loss: 3.843066 Detection Loss: 0.007124 Recognition Loss:3.835942\n",
      "Train Epoch: 5 [416/904 (46%)] Loss: 4.085904 Detection Loss: 0.004998 Recognition Loss:4.080906\n",
      "Train Epoch: 5 [432/904 (48%)] Loss: 3.807942 Detection Loss: 0.010306 Recognition Loss:3.797637\n",
      "Train Epoch: 5 [448/904 (50%)] Loss: 3.686713 Detection Loss: 0.007430 Recognition Loss:3.679283\n",
      "Train Epoch: 5 [464/904 (51%)] Loss: 3.952880 Detection Loss: 0.007341 Recognition Loss:3.945539\n",
      "Train Epoch: 5 [480/904 (53%)] Loss: 3.967840 Detection Loss: 0.008753 Recognition Loss:3.959087\n",
      "Train Epoch: 5 [496/904 (55%)] Loss: 3.738068 Detection Loss: 0.005151 Recognition Loss:3.732918\n",
      "Train Epoch: 5 [512/904 (57%)] Loss: 3.881165 Detection Loss: 0.017397 Recognition Loss:3.863768\n",
      "Train Epoch: 5 [528/904 (58%)] Loss: 3.855357 Detection Loss: 0.006419 Recognition Loss:3.848938\n",
      "Train Epoch: 5 [544/904 (60%)] Loss: 4.010315 Detection Loss: 0.007376 Recognition Loss:4.002939\n",
      "Train Epoch: 5 [560/904 (62%)] Loss: 3.933155 Detection Loss: 0.009571 Recognition Loss:3.923584\n",
      "Train Epoch: 5 [576/904 (64%)] Loss: 3.789076 Detection Loss: 0.005215 Recognition Loss:3.783861\n",
      "Train Epoch: 5 [592/904 (65%)] Loss: 4.077131 Detection Loss: 0.006170 Recognition Loss:4.070962\n",
      "Train Epoch: 5 [608/904 (67%)] Loss: 3.798917 Detection Loss: 0.007660 Recognition Loss:3.791257\n",
      "Train Epoch: 5 [624/904 (69%)] Loss: 3.559755 Detection Loss: 0.017976 Recognition Loss:3.541780\n",
      "Train Epoch: 5 [640/904 (71%)] Loss: 4.341985 Detection Loss: 0.007728 Recognition Loss:4.334258\n",
      "Train Epoch: 5 [656/904 (73%)] Loss: 4.005322 Detection Loss: 0.008354 Recognition Loss:3.996969\n",
      "Train Epoch: 5 [672/904 (74%)] Loss: 3.768574 Detection Loss: 0.005872 Recognition Loss:3.762701\n",
      "Train Epoch: 5 [688/904 (76%)] Loss: 3.939141 Detection Loss: 0.005734 Recognition Loss:3.933407\n",
      "Train Epoch: 5 [704/904 (78%)] Loss: 3.850361 Detection Loss: 0.009126 Recognition Loss:3.841235\n",
      "Train Epoch: 5 [720/904 (80%)] Loss: 4.145532 Detection Loss: 0.009538 Recognition Loss:4.135994\n",
      "Train Epoch: 5 [736/904 (81%)] Loss: 4.046947 Detection Loss: 0.005662 Recognition Loss:4.041285\n",
      "Train Epoch: 5 [752/904 (83%)] Loss: 4.007522 Detection Loss: 0.007893 Recognition Loss:3.999629\n",
      "Train Epoch: 5 [768/904 (85%)] Loss: 4.179430 Detection Loss: 0.005904 Recognition Loss:4.173526\n",
      "Train Epoch: 5 [784/904 (87%)] Loss: 3.889437 Detection Loss: 0.009100 Recognition Loss:3.880337\n",
      "Train Epoch: 5 [800/904 (88%)] Loss: 3.924721 Detection Loss: 0.008122 Recognition Loss:3.916599\n",
      "Train Epoch: 5 [816/904 (90%)] Loss: 3.923886 Detection Loss: 0.013844 Recognition Loss:3.910042\n",
      "Train Epoch: 5 [832/904 (92%)] Loss: 4.035075 Detection Loss: 0.008705 Recognition Loss:4.026370\n",
      "Train Epoch: 5 [848/904 (94%)] Loss: 3.867456 Detection Loss: 0.006052 Recognition Loss:3.861403\n",
      "Train Epoch: 5 [864/904 (96%)] Loss: 3.952474 Detection Loss: 0.005904 Recognition Loss:3.946571\n",
      "Train Epoch: 5 [880/904 (97%)] Loss: 3.773194 Detection Loss: 0.006571 Recognition Loss:3.766623\n",
      "Train Epoch: 5 [896/904 (99%)] Loss: 3.867197 Detection Loss: 0.006232 Recognition Loss:3.860965\n",
      "Start validate\n",
      "    epoch          : 5\n",
      "    loss           : 3.904666527182655\n",
      "    det_loss       : 0.008876530626640382\n",
      "    rec_loss       : 3.895789990382912\n",
      "    precious       : 0.0\n",
      "    recall         : 0.0\n",
      "    hmean          : 0.0\n",
      "    val_loss       : 3.9958736955976257\n",
      "    val_det_loss   : 0.009998987715404768\n",
      "    val_rec_loss   : 3.9858747078822208\n",
      "    val_precious   : 0.0\n",
      "    val_recall     : 0.0\n",
      "    val_hmean      : 0.0\n",
      "Saving current best: model_best.pth.tar ...\n",
      "Saving checkpoint: ../saved/FOTS/checkpoint-epoch005-loss-3.9047.pth.tar ...\n",
      "Train Epoch: 6 [0/904 (0%)] Loss: 3.808438 Detection Loss: 0.007202 Recognition Loss:3.801236\n",
      "Train Epoch: 6 [16/904 (2%)] Loss: 3.628425 Detection Loss: 0.007582 Recognition Loss:3.620842\n",
      "Train Epoch: 6 [32/904 (4%)] Loss: 3.726689 Detection Loss: 0.006930 Recognition Loss:3.719759\n",
      "Train Epoch: 6 [48/904 (5%)] Loss: 4.034006 Detection Loss: 0.017050 Recognition Loss:4.016956\n",
      "Train Epoch: 6 [64/904 (7%)] Loss: 3.820440 Detection Loss: 0.009445 Recognition Loss:3.810996\n",
      "Train Epoch: 6 [80/904 (9%)] Loss: 3.932800 Detection Loss: 0.017220 Recognition Loss:3.915579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [96/904 (11%)] Loss: 3.713434 Detection Loss: 0.005328 Recognition Loss:3.708106\n",
      "Train Epoch: 6 [112/904 (12%)] Loss: 3.573977 Detection Loss: 0.007555 Recognition Loss:3.566422\n",
      "Train Epoch: 6 [128/904 (14%)] Loss: 3.857183 Detection Loss: 0.007668 Recognition Loss:3.849514\n",
      "Train Epoch: 6 [144/904 (16%)] Loss: 4.015279 Detection Loss: 0.012869 Recognition Loss:4.002410\n",
      "Train Epoch: 6 [160/904 (18%)] Loss: 3.849253 Detection Loss: 0.008246 Recognition Loss:3.841007\n",
      "Train Epoch: 6 [176/904 (19%)] Loss: 3.630142 Detection Loss: 0.008022 Recognition Loss:3.622120\n",
      "Train Epoch: 6 [192/904 (21%)] Loss: 3.475477 Detection Loss: 0.007873 Recognition Loss:3.467604\n",
      "Train Epoch: 6 [208/904 (23%)] Loss: 3.983354 Detection Loss: 0.005193 Recognition Loss:3.978160\n",
      "Train Epoch: 6 [224/904 (25%)] Loss: 4.156964 Detection Loss: 0.006525 Recognition Loss:4.150439\n",
      "Train Epoch: 6 [240/904 (27%)] Loss: 4.220485 Detection Loss: 0.004765 Recognition Loss:4.215719\n",
      "Train Epoch: 6 [256/904 (28%)] Loss: 3.835013 Detection Loss: 0.005855 Recognition Loss:3.829158\n",
      "Train Epoch: 6 [272/904 (30%)] Loss: 3.853943 Detection Loss: 0.035150 Recognition Loss:3.818793\n",
      "Train Epoch: 6 [288/904 (32%)] Loss: 3.786992 Detection Loss: 0.005709 Recognition Loss:3.781283\n",
      "Train Epoch: 6 [304/904 (34%)] Loss: 4.038646 Detection Loss: 0.008892 Recognition Loss:4.029754\n",
      "Train Epoch: 6 [320/904 (35%)] Loss: 4.082783 Detection Loss: 0.006010 Recognition Loss:4.076774\n",
      "Train Epoch: 6 [336/904 (37%)] Loss: 3.937584 Detection Loss: 0.007932 Recognition Loss:3.929653\n",
      "Train Epoch: 6 [352/904 (39%)] Loss: 3.862921 Detection Loss: 0.012266 Recognition Loss:3.850655\n",
      "Train Epoch: 6 [368/904 (41%)] Loss: 3.867287 Detection Loss: 0.005662 Recognition Loss:3.861626\n",
      "Train Epoch: 6 [384/904 (42%)] Loss: 3.598611 Detection Loss: 0.007197 Recognition Loss:3.591414\n",
      "Train Epoch: 6 [400/904 (44%)] Loss: 4.000904 Detection Loss: 0.013313 Recognition Loss:3.987591\n",
      "Train Epoch: 6 [416/904 (46%)] Loss: 3.888407 Detection Loss: 0.006884 Recognition Loss:3.881523\n",
      "Train Epoch: 6 [432/904 (48%)] Loss: 4.065202 Detection Loss: 0.013661 Recognition Loss:4.051540\n",
      "Train Epoch: 6 [448/904 (50%)] Loss: 3.826663 Detection Loss: 0.005813 Recognition Loss:3.820850\n",
      "Train Epoch: 6 [464/904 (51%)] Loss: 3.660506 Detection Loss: 0.008205 Recognition Loss:3.652301\n",
      "Train Epoch: 6 [480/904 (53%)] Loss: 3.768524 Detection Loss: 0.011112 Recognition Loss:3.757412\n",
      "Train Epoch: 6 [496/904 (55%)] Loss: 3.650630 Detection Loss: 0.004784 Recognition Loss:3.645846\n",
      "Train Epoch: 6 [512/904 (57%)] Loss: 4.030589 Detection Loss: 0.012121 Recognition Loss:4.018467\n",
      "Train Epoch: 6 [528/904 (58%)] Loss: 3.943100 Detection Loss: 0.008613 Recognition Loss:3.934488\n",
      "Train Epoch: 6 [544/904 (60%)] Loss: 4.042043 Detection Loss: 0.012979 Recognition Loss:4.029064\n",
      "Train Epoch: 6 [560/904 (62%)] Loss: 3.886198 Detection Loss: 0.009081 Recognition Loss:3.877117\n",
      "Train Epoch: 6 [576/904 (64%)] Loss: 4.077183 Detection Loss: 0.006565 Recognition Loss:4.070618\n",
      "Train Epoch: 6 [592/904 (65%)] Loss: 3.740108 Detection Loss: 0.013312 Recognition Loss:3.726795\n",
      "Train Epoch: 6 [608/904 (67%)] Loss: 3.926620 Detection Loss: 0.006002 Recognition Loss:3.920618\n",
      "Train Epoch: 6 [624/904 (69%)] Loss: 3.743717 Detection Loss: 0.010194 Recognition Loss:3.733523\n",
      "Train Epoch: 6 [640/904 (71%)] Loss: 3.935834 Detection Loss: 0.012968 Recognition Loss:3.922866\n",
      "Train Epoch: 6 [656/904 (73%)] Loss: 4.260620 Detection Loss: 0.007422 Recognition Loss:4.253198\n",
      "Train Epoch: 6 [672/904 (74%)] Loss: 4.001436 Detection Loss: 0.008874 Recognition Loss:3.992563\n",
      "Train Epoch: 6 [688/904 (76%)] Loss: 3.696496 Detection Loss: 0.009325 Recognition Loss:3.687170\n",
      "Train Epoch: 6 [704/904 (78%)] Loss: 3.782901 Detection Loss: 0.016838 Recognition Loss:3.766063\n",
      "Train Epoch: 6 [720/904 (80%)] Loss: 3.872828 Detection Loss: 0.007347 Recognition Loss:3.865481\n",
      "Train Epoch: 6 [736/904 (81%)] Loss: 3.592125 Detection Loss: 0.008244 Recognition Loss:3.583881\n",
      "Train Epoch: 6 [752/904 (83%)] Loss: 3.846520 Detection Loss: 0.015663 Recognition Loss:3.830858\n",
      "Train Epoch: 6 [768/904 (85%)] Loss: 3.905627 Detection Loss: 0.010202 Recognition Loss:3.895425\n",
      "Train Epoch: 6 [784/904 (87%)] Loss: 4.064785 Detection Loss: 0.007037 Recognition Loss:4.057748\n",
      "Train Epoch: 6 [800/904 (88%)] Loss: 3.687457 Detection Loss: 0.008863 Recognition Loss:3.678594\n",
      "Train Epoch: 6 [816/904 (90%)] Loss: 3.585380 Detection Loss: 0.009737 Recognition Loss:3.575643\n",
      "Train Epoch: 6 [832/904 (92%)] Loss: 3.713752 Detection Loss: 0.007175 Recognition Loss:3.706577\n",
      "Train Epoch: 6 [848/904 (94%)] Loss: 3.910653 Detection Loss: 0.005622 Recognition Loss:3.905031\n",
      "Train Epoch: 6 [864/904 (96%)] Loss: 3.742491 Detection Loss: 0.007438 Recognition Loss:3.735053\n",
      "Train Epoch: 6 [880/904 (97%)] Loss: 3.663351 Detection Loss: 0.006696 Recognition Loss:3.656655\n",
      "Train Epoch: 6 [896/904 (99%)] Loss: 3.957531 Detection Loss: 0.007463 Recognition Loss:3.950068\n",
      "Start validate\n",
      "    epoch          : 6\n",
      "    loss           : 3.869350327854663\n",
      "    det_loss       : 0.009098942515201273\n",
      "    rec_loss       : 3.860251403487889\n",
      "    precious       : 0.0\n",
      "    recall         : 0.0\n",
      "    hmean          : 0.0\n",
      "    val_loss       : 4.058794426015363\n",
      "    val_det_loss   : 0.010115074208722664\n",
      "    val_rec_loss   : 4.048679351806641\n",
      "    val_precious   : 0.0\n",
      "    val_recall     : 0.0\n",
      "    val_hmean      : 0.0\n",
      "Saving current best: model_best.pth.tar ...\n",
      "Saving checkpoint: ../saved/FOTS/checkpoint-epoch006-loss-3.8694.pth.tar ...\n",
      "Train Epoch: 7 [0/904 (0%)] Loss: 4.062397 Detection Loss: 0.005551 Recognition Loss:4.056846\n",
      "Train Epoch: 7 [16/904 (2%)] Loss: 3.665091 Detection Loss: 0.010082 Recognition Loss:3.655009\n",
      "Train Epoch: 7 [32/904 (4%)] Loss: 3.914361 Detection Loss: 0.010944 Recognition Loss:3.903416\n",
      "Train Epoch: 7 [48/904 (5%)] Loss: 3.809359 Detection Loss: 0.004944 Recognition Loss:3.804415\n",
      "Train Epoch: 7 [64/904 (7%)] Loss: 4.077500 Detection Loss: 0.010843 Recognition Loss:4.066657\n",
      "Train Epoch: 7 [80/904 (9%)] Loss: 4.125063 Detection Loss: 0.005720 Recognition Loss:4.119343\n",
      "Train Epoch: 7 [96/904 (11%)] Loss: 3.994450 Detection Loss: 0.008816 Recognition Loss:3.985634\n",
      "Train Epoch: 7 [112/904 (12%)] Loss: 3.906050 Detection Loss: 0.011132 Recognition Loss:3.894919\n",
      "Train Epoch: 7 [128/904 (14%)] Loss: 3.690472 Detection Loss: 0.005656 Recognition Loss:3.684816\n",
      "Train Epoch: 7 [144/904 (16%)] Loss: 3.980348 Detection Loss: 0.009261 Recognition Loss:3.971087\n",
      "Train Epoch: 7 [160/904 (18%)] Loss: 4.060344 Detection Loss: 0.006250 Recognition Loss:4.054094\n",
      "Train Epoch: 7 [176/904 (19%)] Loss: 4.191503 Detection Loss: 0.011984 Recognition Loss:4.179519\n",
      "Train Epoch: 7 [192/904 (21%)] Loss: 3.567485 Detection Loss: 0.008182 Recognition Loss:3.559303\n",
      "Train Epoch: 7 [208/904 (23%)] Loss: 3.377333 Detection Loss: 0.009217 Recognition Loss:3.368116\n",
      "Train Epoch: 7 [224/904 (25%)] Loss: 3.785466 Detection Loss: 0.010187 Recognition Loss:3.775280\n",
      "Train Epoch: 7 [240/904 (27%)] Loss: 3.790047 Detection Loss: 0.005873 Recognition Loss:3.784175\n",
      "Train Epoch: 7 [256/904 (28%)] Loss: 3.643311 Detection Loss: 0.005933 Recognition Loss:3.637378\n",
      "Train Epoch: 7 [272/904 (30%)] Loss: 3.719516 Detection Loss: 0.006571 Recognition Loss:3.712945\n",
      "Train Epoch: 7 [288/904 (32%)] Loss: 3.999682 Detection Loss: 0.006836 Recognition Loss:3.992846\n",
      "Train Epoch: 7 [304/904 (34%)] Loss: 3.921831 Detection Loss: 0.009235 Recognition Loss:3.912596\n",
      "Train Epoch: 7 [320/904 (35%)] Loss: 3.597233 Detection Loss: 0.008988 Recognition Loss:3.588245\n",
      "Train Epoch: 7 [336/904 (37%)] Loss: 3.889529 Detection Loss: 0.008904 Recognition Loss:3.880625\n",
      "Train Epoch: 7 [352/904 (39%)] Loss: 3.748918 Detection Loss: 0.006523 Recognition Loss:3.742394\n",
      "Train Epoch: 7 [368/904 (41%)] Loss: 3.706590 Detection Loss: 0.007676 Recognition Loss:3.698915\n",
      "Train Epoch: 7 [384/904 (42%)] Loss: 3.865026 Detection Loss: 0.011695 Recognition Loss:3.853331\n",
      "Train Epoch: 7 [400/904 (44%)] Loss: 3.563292 Detection Loss: 0.005809 Recognition Loss:3.557482\n",
      "Train Epoch: 7 [416/904 (46%)] Loss: 3.913269 Detection Loss: 0.008910 Recognition Loss:3.904359\n",
      "Train Epoch: 7 [432/904 (48%)] Loss: 3.943770 Detection Loss: 0.006805 Recognition Loss:3.936965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [448/904 (50%)] Loss: 3.948334 Detection Loss: 0.006711 Recognition Loss:3.941622\n",
      "Train Epoch: 7 [464/904 (51%)] Loss: 3.961728 Detection Loss: 0.006311 Recognition Loss:3.955416\n",
      "Train Epoch: 7 [480/904 (53%)] Loss: 3.674404 Detection Loss: 0.008887 Recognition Loss:3.665516\n",
      "Train Epoch: 7 [496/904 (55%)] Loss: 4.073764 Detection Loss: 0.006989 Recognition Loss:4.066775\n",
      "Train Epoch: 7 [512/904 (57%)] Loss: 3.954272 Detection Loss: 0.006450 Recognition Loss:3.947821\n",
      "Train Epoch: 7 [528/904 (58%)] Loss: 3.635268 Detection Loss: 0.006248 Recognition Loss:3.629020\n",
      "Train Epoch: 7 [544/904 (60%)] Loss: 3.804710 Detection Loss: 0.007682 Recognition Loss:3.797027\n",
      "Train Epoch: 7 [560/904 (62%)] Loss: 3.867385 Detection Loss: 0.011113 Recognition Loss:3.856272\n",
      "Train Epoch: 7 [576/904 (64%)] Loss: 4.082091 Detection Loss: 0.009488 Recognition Loss:4.072603\n",
      "Train Epoch: 7 [592/904 (65%)] Loss: 3.953117 Detection Loss: 0.008442 Recognition Loss:3.944675\n",
      "Train Epoch: 7 [608/904 (67%)] Loss: 3.694188 Detection Loss: 0.008788 Recognition Loss:3.685401\n",
      "Train Epoch: 7 [624/904 (69%)] Loss: 3.673602 Detection Loss: 0.008401 Recognition Loss:3.665201\n",
      "Train Epoch: 7 [640/904 (71%)] Loss: 3.860211 Detection Loss: 0.009765 Recognition Loss:3.850445\n",
      "Train Epoch: 7 [656/904 (73%)] Loss: 3.860955 Detection Loss: 0.011048 Recognition Loss:3.849906\n",
      "Train Epoch: 7 [672/904 (74%)] Loss: 3.800667 Detection Loss: 0.007992 Recognition Loss:3.792675\n",
      "Train Epoch: 7 [688/904 (76%)] Loss: 3.865536 Detection Loss: 0.005568 Recognition Loss:3.859968\n",
      "Train Epoch: 7 [704/904 (78%)] Loss: 3.881289 Detection Loss: 0.027588 Recognition Loss:3.853701\n",
      "Train Epoch: 7 [720/904 (80%)] Loss: 3.789535 Detection Loss: 0.008786 Recognition Loss:3.780749\n",
      "Train Epoch: 7 [736/904 (81%)] Loss: 3.548638 Detection Loss: 0.014023 Recognition Loss:3.534615\n",
      "Train Epoch: 7 [752/904 (83%)] Loss: 3.678320 Detection Loss: 0.008701 Recognition Loss:3.669619\n",
      "Train Epoch: 7 [768/904 (85%)] Loss: 3.564671 Detection Loss: 0.016228 Recognition Loss:3.548443\n",
      "Train Epoch: 7 [784/904 (87%)] Loss: 3.858807 Detection Loss: 0.011432 Recognition Loss:3.847376\n",
      "Train Epoch: 7 [800/904 (88%)] Loss: 3.784482 Detection Loss: 0.012778 Recognition Loss:3.771704\n",
      "Train Epoch: 7 [816/904 (90%)] Loss: 3.465384 Detection Loss: 0.006465 Recognition Loss:3.458919\n",
      "Train Epoch: 7 [832/904 (92%)] Loss: 3.785936 Detection Loss: 0.007510 Recognition Loss:3.778426\n",
      "Train Epoch: 7 [848/904 (94%)] Loss: 3.192385 Detection Loss: 0.005073 Recognition Loss:3.187312\n",
      "Train Epoch: 7 [864/904 (96%)] Loss: 3.975852 Detection Loss: 0.007167 Recognition Loss:3.968686\n",
      "Train Epoch: 7 [880/904 (97%)] Loss: 3.660274 Detection Loss: 0.008697 Recognition Loss:3.651577\n",
      "Train Epoch: 7 [896/904 (99%)] Loss: 3.823778 Detection Loss: 0.006152 Recognition Loss:3.817625\n",
      "Start validate\n",
      "    epoch          : 7\n",
      "    loss           : 3.829409244841179\n",
      "    det_loss       : 0.009197199993264096\n",
      "    rec_loss       : 3.82021204349214\n",
      "    precious       : 0.0\n",
      "    recall         : 0.0\n",
      "    hmean          : 0.0\n",
      "    val_loss       : 3.974555611395492\n",
      "    val_det_loss   : 0.010502163965541583\n",
      "    val_rec_loss   : 3.9640534474299502\n",
      "    val_precious   : 0.0\n",
      "    val_recall     : 0.0\n",
      "    val_hmean      : 0.0\n",
      "Saving current best: model_best.pth.tar ...\n",
      "Saving checkpoint: ../saved/FOTS/checkpoint-epoch007-loss-3.8294.pth.tar ...\n",
      "Train Epoch: 8 [0/904 (0%)] Loss: 3.626212 Detection Loss: 0.007940 Recognition Loss:3.618271\n",
      "Train Epoch: 8 [16/904 (2%)] Loss: 3.968857 Detection Loss: 0.009257 Recognition Loss:3.959600\n",
      "Train Epoch: 8 [32/904 (4%)] Loss: 3.822829 Detection Loss: 0.013515 Recognition Loss:3.809314\n",
      "Train Epoch: 8 [48/904 (5%)] Loss: 3.556197 Detection Loss: 0.010283 Recognition Loss:3.545915\n",
      "Train Epoch: 8 [64/904 (7%)] Loss: 3.573329 Detection Loss: 0.008222 Recognition Loss:3.565107\n",
      "Train Epoch: 8 [80/904 (9%)] Loss: 3.699096 Detection Loss: 0.009458 Recognition Loss:3.689639\n",
      "Train Epoch: 8 [96/904 (11%)] Loss: 3.638491 Detection Loss: 0.006736 Recognition Loss:3.631756\n",
      "Train Epoch: 8 [112/904 (12%)] Loss: 3.883037 Detection Loss: 0.009640 Recognition Loss:3.873397\n",
      "Train Epoch: 8 [128/904 (14%)] Loss: 3.967119 Detection Loss: 0.007644 Recognition Loss:3.959475\n",
      "Train Epoch: 8 [144/904 (16%)] Loss: 4.032962 Detection Loss: 0.013059 Recognition Loss:4.019904\n",
      "Train Epoch: 8 [160/904 (18%)] Loss: 3.846214 Detection Loss: 0.009426 Recognition Loss:3.836788\n",
      "Train Epoch: 8 [176/904 (19%)] Loss: 3.358637 Detection Loss: 0.005817 Recognition Loss:3.352820\n",
      "Train Epoch: 8 [192/904 (21%)] Loss: 4.022663 Detection Loss: 0.008173 Recognition Loss:4.014491\n",
      "Train Epoch: 8 [208/904 (23%)] Loss: 3.752346 Detection Loss: 0.007053 Recognition Loss:3.745293\n",
      "Train Epoch: 8 [224/904 (25%)] Loss: 4.122612 Detection Loss: 0.009090 Recognition Loss:4.113522\n",
      "Train Epoch: 8 [240/904 (27%)] Loss: 3.794960 Detection Loss: 0.005880 Recognition Loss:3.789080\n",
      "Train Epoch: 8 [256/904 (28%)] Loss: 3.875011 Detection Loss: 0.010854 Recognition Loss:3.864157\n",
      "Train Epoch: 8 [272/904 (30%)] Loss: 3.808283 Detection Loss: 0.012138 Recognition Loss:3.796145\n",
      "Train Epoch: 8 [288/904 (32%)] Loss: 4.529509 Detection Loss: 0.011379 Recognition Loss:4.518129\n",
      "Train Epoch: 8 [304/904 (34%)] Loss: 3.858413 Detection Loss: 0.010284 Recognition Loss:3.848130\n",
      "Train Epoch: 8 [320/904 (35%)] Loss: 3.847081 Detection Loss: 0.007331 Recognition Loss:3.839750\n",
      "Train Epoch: 8 [336/904 (37%)] Loss: 3.940681 Detection Loss: 0.004648 Recognition Loss:3.936033\n",
      "Train Epoch: 8 [352/904 (39%)] Loss: 3.833801 Detection Loss: 0.007178 Recognition Loss:3.826622\n",
      "Train Epoch: 8 [368/904 (41%)] Loss: 3.681909 Detection Loss: 0.008127 Recognition Loss:3.673782\n",
      "Train Epoch: 8 [384/904 (42%)] Loss: 3.631737 Detection Loss: 0.007645 Recognition Loss:3.624092\n",
      "Train Epoch: 8 [400/904 (44%)] Loss: 3.854287 Detection Loss: 0.010935 Recognition Loss:3.843353\n",
      "Train Epoch: 8 [416/904 (46%)] Loss: 3.762069 Detection Loss: 0.011199 Recognition Loss:3.750870\n",
      "Train Epoch: 8 [432/904 (48%)] Loss: 3.869131 Detection Loss: 0.007718 Recognition Loss:3.861413\n",
      "Train Epoch: 8 [448/904 (50%)] Loss: 3.830478 Detection Loss: 0.008599 Recognition Loss:3.821879\n",
      "Train Epoch: 8 [464/904 (51%)] Loss: 3.936617 Detection Loss: 0.011028 Recognition Loss:3.925590\n",
      "Train Epoch: 8 [480/904 (53%)] Loss: 4.017212 Detection Loss: 0.008822 Recognition Loss:4.008390\n",
      "Train Epoch: 8 [496/904 (55%)] Loss: 3.663911 Detection Loss: 0.015731 Recognition Loss:3.648180\n",
      "Train Epoch: 8 [512/904 (57%)] Loss: 3.565469 Detection Loss: 0.007736 Recognition Loss:3.557733\n",
      "Train Epoch: 8 [528/904 (58%)] Loss: 3.874906 Detection Loss: 0.009654 Recognition Loss:3.865252\n",
      "Train Epoch: 8 [544/904 (60%)] Loss: 3.866766 Detection Loss: 0.019762 Recognition Loss:3.847005\n",
      "Train Epoch: 8 [560/904 (62%)] Loss: 4.080016 Detection Loss: 0.010421 Recognition Loss:4.069595\n",
      "Train Epoch: 8 [576/904 (64%)] Loss: 3.978495 Detection Loss: 0.006880 Recognition Loss:3.971615\n",
      "Train Epoch: 8 [592/904 (65%)] Loss: 3.859686 Detection Loss: 0.013667 Recognition Loss:3.846019\n",
      "Train Epoch: 8 [608/904 (67%)] Loss: 3.689323 Detection Loss: 0.006294 Recognition Loss:3.683030\n",
      "Train Epoch: 8 [624/904 (69%)] Loss: 3.725682 Detection Loss: 0.006471 Recognition Loss:3.719210\n",
      "Train Epoch: 8 [640/904 (71%)] Loss: 3.737329 Detection Loss: 0.007924 Recognition Loss:3.729405\n",
      "Train Epoch: 8 [656/904 (73%)] Loss: 3.894494 Detection Loss: 0.006930 Recognition Loss:3.887564\n",
      "Train Epoch: 8 [672/904 (74%)] Loss: 3.748950 Detection Loss: 0.008210 Recognition Loss:3.740740\n",
      "Train Epoch: 8 [688/904 (76%)] Loss: 3.445567 Detection Loss: 0.007776 Recognition Loss:3.437792\n",
      "Train Epoch: 8 [704/904 (78%)] Loss: 3.785801 Detection Loss: 0.005842 Recognition Loss:3.779959\n",
      "Train Epoch: 8 [720/904 (80%)] Loss: 3.840523 Detection Loss: 0.008794 Recognition Loss:3.831729\n",
      "Train Epoch: 8 [736/904 (81%)] Loss: 3.459370 Detection Loss: 0.011005 Recognition Loss:3.448365\n",
      "Train Epoch: 8 [752/904 (83%)] Loss: 4.029797 Detection Loss: 0.010524 Recognition Loss:4.019272\n",
      "Train Epoch: 8 [768/904 (85%)] Loss: 3.905862 Detection Loss: 0.009225 Recognition Loss:3.896637\n",
      "Train Epoch: 8 [784/904 (87%)] Loss: 3.867564 Detection Loss: 0.008294 Recognition Loss:3.859270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [800/904 (88%)] Loss: 4.003519 Detection Loss: 0.008557 Recognition Loss:3.994962\n",
      "Train Epoch: 8 [816/904 (90%)] Loss: 3.918893 Detection Loss: 0.009841 Recognition Loss:3.909052\n",
      "Train Epoch: 8 [832/904 (92%)] Loss: 3.951806 Detection Loss: 0.008340 Recognition Loss:3.943466\n",
      "Train Epoch: 8 [848/904 (94%)] Loss: 3.716156 Detection Loss: 0.008073 Recognition Loss:3.708083\n",
      "Train Epoch: 8 [864/904 (96%)] Loss: 3.688466 Detection Loss: 0.007062 Recognition Loss:3.681404\n",
      "Train Epoch: 8 [880/904 (97%)] Loss: 3.873015 Detection Loss: 0.007114 Recognition Loss:3.865901\n",
      "Train Epoch: 8 [896/904 (99%)] Loss: 3.670913 Detection Loss: 0.009622 Recognition Loss:3.661290\n",
      "Start validate\n"
     ]
    }
   ],
   "source": [
    "# with roi rotate and with moran\n",
    "!python3 train.py --config=\"configs/config.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make: Entering directory '/home/dmivanov/end2end_OCR/utils/lanms'\n",
      "make: 'adaptor.so' is up to date.\n",
      "make: Leaving directory '/home/dmivanov/end2end_OCR/utils/lanms'\n",
      "0it [00:00, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 108, in <module>\n",
      "    main(config, args.resume, config_from_file)\n",
      "  File \"train.py\", line 28, in main\n",
      "    train = data_loader.train()\n",
      "  File \"/home/dmivanov/end2end_OCR/data_loader/data_loaders.py\", line 63, in train\n",
      "    shuffle = self.shuffle, collate_fn = collate_fn)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 802, in __init__\n",
      "    sampler = RandomSampler(dataset)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/sampler.py\", line 64, in __init__\n",
      "    \"value, but got num_samples={}\".format(self.num_samples))\n",
      "ValueError: num_samples should be a positive integeral value, but got num_samples=0\n"
     ]
    }
   ],
   "source": [
    "# with roi rotate and without moran\n",
    "!python3 train.py --config=\"configs/config.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"/data/ivpaharitonov\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make: Entering directory '/home/dmivanov/end2end_OCR/utils/lanms'\n",
      "make: 'adaptor.so' is up to date.\n",
      "make: Leaving directory '/home/dmivanov/end2end_OCR/utils/lanms'\n",
      "Loading checkpoint: /data/ivpaharitonov/checkpoints/saved_icdar_2017/FOTS/checkpoint-epoch015-loss-1.9341.pth.tar ...\n",
      "start evaluation\n",
      "  0%|                                                   | 0/500 [00:00<?, ?it/s]-----------------------------------------------\n",
      "\n",
      "Image name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/ch4_test_images/img_1.jpg\n",
      "\n",
      "Annotation name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/Challenge4_Test_Task4_GT/gt_img_1.txt\n",
      "\n",
      "['###', '###', '###', '###', '###', '###', '###', '###']\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2351: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2423: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "Predicted texts: ['HTE']\n",
      "\n",
      "res:  (0, 8, 0, 0, 0)\n",
      "Image true word count: 0\n",
      "Image not ignored word count: 0\n",
      "Image word accuracy (for not ignored): all ignored\n",
      "Levenshtein distance: 0\n",
      "\n",
      "  0%|                                           | 1/500 [00:03<30:54,  3.72s/it]-----------------------------------------------\n",
      "\n",
      "Image name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/ch4_test_images/img_10.jpg\n",
      "\n",
      "Annotation name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/Challenge4_Test_Task4_GT/gt_img_10.txt\n",
      "\n",
      "['Please', 'lower', 'your', 'volume', 'when', 'you', 'pass', '###', 'residential', 'areas']\n",
      "\n",
      "Predicted texts: []\n",
      "\n",
      "res:  (0, 0, 9, 0, 0)\n",
      "Image true word count: 0\n",
      "Image not ignored word count: 9\n",
      "Image word accuracy (for not ignored): 0.0\n",
      "Levenshtein distance: 0\n",
      "\n",
      "  0%|▏                                          | 2/500 [00:05<25:33,  3.08s/it]-----------------------------------------------\n",
      "\n",
      "Image name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/ch4_test_images/img_100.jpg\n",
      "\n",
      "Annotation name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/Challenge4_Test_Task4_GT/gt_img_100.txt\n",
      "\n",
      "['###', 'diverse', 'tastes', '###', 'flavours', 'the', 'Refishing', 'DINING', '###', '###', 'DINING', '###']\n",
      "\n",
      "Predicted texts: ['FEEES', 'EE', 'er']\n",
      "\n",
      "res:  (1, 28, 7, 0, 0.875)\n",
      "Image true word count: 0\n",
      "Image not ignored word count: 7\n",
      "Image word accuracy (for not ignored): 0.0\n",
      "Levenshtein distance: 0.875\n",
      "\n",
      "  1%|▎                                          | 3/500 [00:08<25:46,  3.11s/it]-----------------------------------------------\n",
      "\n",
      "Image name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/ch4_test_images/img_101.jpg\n",
      "\n",
      "Annotation name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/Challenge4_Test_Task4_GT/gt_img_101.txt\n",
      "\n",
      "['SALE', 'MARC', '###']\n",
      "\n",
      "Predicted texts: []\n",
      "\n",
      "res:  (0, 0, 2, 0, 0)\n",
      "Image true word count: 0\n",
      "Image not ignored word count: 2\n",
      "Image word accuracy (for not ignored): 0.0\n",
      "Levenshtein distance: 0\n",
      "\n",
      "  1%|▎                                          | 4/500 [00:10<21:54,  2.65s/it]-----------------------------------------------\n",
      "\n",
      "Image name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/ch4_test_images/img_102.jpg\n",
      "\n",
      "Annotation name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/Challenge4_Test_Task4_GT/gt_img_102.txt\n",
      "\n",
      "['ST.MARC', 'CAFE', '###', '###']\n",
      "\n",
      "Predicted texts: ['CRE']\n",
      "\n",
      "res:  (0, 4, 2, 0, 0)\n",
      "Image true word count: 0\n",
      "Image not ignored word count: 2\n",
      "Image word accuracy (for not ignored): 0.0\n",
      "Levenshtein distance: 0\n",
      "\n",
      "  1%|▍                                          | 5/500 [00:13<23:02,  2.79s/it]-----------------------------------------------\n",
      "\n",
      "Image name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/ch4_test_images/img_103.jpg\n",
      "\n",
      "Annotation name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/Challenge4_Test_Task4_GT/gt_img_103.txt\n",
      "\n",
      "['###', '###', '###', '###', '###', 'EXIT', '###', 'ANGKOK', '###', 'KOK', 'ABUR', '###', '###', '###', '###', '###', 'PATH', '###', 'CHAT', '###', '###', '###', '###', '###', '###']\n",
      "\n",
      "Predicted texts: ['T', '6O']\n",
      "\n",
      "res:  (1, 31, 6, 0, 1.0)\n",
      "Image true word count: 0\n",
      "Image not ignored word count: 6\n",
      "Image word accuracy (for not ignored): 0.0\n",
      "Levenshtein distance: 1.0\n",
      "\n",
      "  1%|▌                                          | 6/500 [00:16<24:00,  2.92s/it]-----------------------------------------------\n",
      "\n",
      "Image name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/ch4_test_images/img_104.jpg\n",
      "\n",
      "Annotation name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/Challenge4_Test_Task4_GT/gt_img_104.txt\n",
      "\n",
      "['END', '###', 'MILE', 'SPEED', '###', '###', 'gels', '###', '###']\n",
      "\n",
      "Predicted texts: ['TTEIE', 'MEi', 'e']\n",
      "\n",
      "res:  (0, 27, 4, 0, 0)\n",
      "Image true word count: 0\n",
      "Image not ignored word count: 4\n",
      "Image word accuracy (for not ignored): 0.0\n",
      "Levenshtein distance: 0\n",
      "\n",
      "  1%|▌                                          | 7/500 [00:19<24:45,  3.01s/it]-----------------------------------------------\n",
      "\n",
      "Image name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/ch4_test_images/img_105.jpg\n",
      "\n",
      "Annotation name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/Challenge4_Test_Task4_GT/gt_img_105.txt\n",
      "\n",
      "['aigonLotus']\n",
      "\n",
      "Predicted texts: []\n",
      "\n",
      "res:  (0, 0, 1, 0, 0)\n",
      "Image true word count: 0\n",
      "Image not ignored word count: 1\n",
      "Image word accuracy (for not ignored): 0.0\n",
      "Levenshtein distance: 0\n",
      "\n",
      "  2%|▋                                          | 8/500 [00:21<21:10,  2.58s/it]-----------------------------------------------\n",
      "\n",
      "Image name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/ch4_test_images/img_106.jpg\n",
      "\n",
      "Annotation name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/Challenge4_Test_Task4_GT/gt_img_106.txt\n",
      "\n",
      "['###', 'Marina', 'MRT', '###', 'Station', 'Link', 'MARINA', 'LINK', '###', 'PARTI', 'PLAN', '###', '###', '###', '###', '###', '###', '###', '###', '###', '###', '###', '###', '###']\n",
      "\n",
      "Predicted texts: ['TEEEES']\n",
      "\n",
      "res:  (0, 24, 8, 0, 0)\n",
      "Image true word count: 0\n",
      "Image not ignored word count: 8\n",
      "Image word accuracy (for not ignored): 0.0\n",
      "Levenshtein distance: 0\n",
      "\n",
      "  2%|▊                                          | 9/500 [00:24<22:39,  2.77s/it]-----------------------------------------------\n",
      "\n",
      "Image name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/ch4_test_images/img_107.jpg\n",
      "\n",
      "Annotation name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/Challenge4_Test_Task4_GT/gt_img_107.txt\n",
      "\n",
      "['@B1', 'MARINA', 'More', 'MARINA', 'LINK', 'SQUARE', 'Shopping', '&Dining!', '###', '###', '###', '###', '###', '###']\n",
      "\n",
      "Predicted texts: ['CKR', 'K', 'ot']\n",
      "\n",
      "res:  (2, 22, 8, 0, 1.875)\n",
      "Image true word count: 0\n",
      "Image not ignored word count: 8\n",
      "Image word accuracy (for not ignored): 0.0\n",
      "Levenshtein distance: 0.9375\n",
      "\n",
      "  2%|▊                                         | 10/500 [00:27<23:27,  2.87s/it]-----------------------------------------------\n",
      "\n",
      "Image name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/ch4_test_images/img_108.jpg\n",
      "\n",
      "Annotation name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/Challenge4_Test_Task4_GT/gt_img_108.txt\n",
      "\n",
      "['Link', 'B1', '###', 'dining', 'options', 'shopping', '###', 'More', 'Marina', 'This', 'way', '###', 'Esplanade', 'Station', 'MARINA:', 'SQUARE']\n",
      "\n",
      "Predicted texts: ['ESpaT', 'anace', 'Thise', 'wo', 'akr', 'vay', 'pOM', 'sto', 'lagn', 'tei', 'aid', 'ud', 'rl']\n",
      "\n",
      "res:  (4, 176, 13, 0, 3.208333333333333)\n",
      "Image true word count: 0\n",
      "Image not ignored word count: 13\n",
      "Image word accuracy (for not ignored): 0.0\n",
      "Levenshtein distance: 0.8020833333333333\n",
      "\n",
      "  2%|▉                                         | 11/500 [00:31<24:52,  3.05s/it]-----------------------------------------------\n",
      "\n",
      "Image name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/ch4_test_images/img_109.jpg\n",
      "\n",
      "Annotation name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/Challenge4_Test_Task4_GT/gt_img_109.txt\n",
      "\n",
      "['###', 'LOVE', '###', '###', 'Organto', 'LOVE', '###', '###', '###', '###', '###', '###', '###', '###', '###', '###']\n",
      "\n",
      "Predicted texts: ['LONEZZ']\n",
      "\n",
      "res:  (0, 16, 3, 0, 0)\n",
      "Image true word count: 0\n",
      "Image not ignored word count: 3\n",
      "Image word accuracy (for not ignored): 0.0\n",
      "Levenshtein distance: 0\n",
      "\n",
      "  2%|█                                         | 12/500 [00:34<25:01,  3.08s/it]-----------------------------------------------\n",
      "\n",
      "Image name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/ch4_test_images/img_11.jpg\n",
      "\n",
      "Annotation name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/Challenge4_Test_Task4_GT/gt_img_11.txt\n",
      "\n",
      "['BEWARE', '###', 'MAINTENANCE', 'VEICHLES']\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted texts: ['CA', 'p', 'VO']\n",
      "\n",
      "res:  (2, 9, 3, 0, 1.875)\n",
      "Image true word count: 0\n",
      "Image not ignored word count: 3\n",
      "Image word accuracy (for not ignored): 0.0\n",
      "Levenshtein distance: 0.9375\n",
      "\n",
      "  3%|█                                         | 13/500 [00:37<25:28,  3.14s/it]-----------------------------------------------\n",
      "\n",
      "Image name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/ch4_test_images/img_110.jpg\n",
      "\n",
      "Annotation name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/Challenge4_Test_Task4_GT/gt_img_110.txt\n",
      "\n",
      "['STEP', '###', 'CHOOSE', 'YOUR', 'TOPPINGS', 'ORO', '###', '###', '###', '###']\n",
      "\n",
      "Predicted texts: ['COL']\n",
      "\n",
      "res:  (0, 10, 5, 0, 0)\n",
      "Image true word count: 0\n",
      "Image not ignored word count: 5\n",
      "Image word accuracy (for not ignored): 0.0\n",
      "Levenshtein distance: 0\n",
      "\n",
      "  3%|█▏                                        | 14/500 [00:40<25:17,  3.12s/it]-----------------------------------------------\n",
      "\n",
      "Image name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/ch4_test_images/img_111.jpg\n",
      "\n",
      "Annotation name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/Challenge4_Test_Task4_GT/gt_img_111.txt\n",
      "\n",
      "['DEFY', 'EMPIRE', 'DEFY', 'ENA E', '###', '###', '###', '###', '###']\n",
      "\n",
      "Predicted texts: []\n",
      "\n",
      "res:  (0, 0, 4, 0, 0)\n",
      "Image true word count: 0\n",
      "Image not ignored word count: 4\n",
      "Image word accuracy (for not ignored): 0.0\n",
      "Levenshtein distance: 0\n",
      "\n",
      "  3%|█▎                                        | 15/500 [00:42<21:29,  2.66s/it]-----------------------------------------------\n",
      "\n",
      "Image name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/ch4_test_images/img_112.jpg\n",
      "\n",
      "Annotation name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/Challenge4_Test_Task4_GT/gt_img_112.txt\n",
      "\n",
      "['Gold', '###', 'CLASS', 'East', 'VILLAGE', 'Wing', 'GOLDEN', 'Level 3', 'next', 'GOLD', 'HABA', 'grab', '#GVSuntecCity', '###', '###', '###', '###', '###', 'LUSH', '###', '###', '###']\n",
      "\n",
      "Predicted texts: ['OE', 'HO', 'C']\n",
      "\n",
      "res:  (3, 8, 13, 0, 2.8333333333333335)\n",
      "Image true word count: 0\n",
      "Image not ignored word count: 13\n",
      "Image word accuracy (for not ignored): 0.0\n",
      "Levenshtein distance: 0.9444444444444445\n",
      "\n",
      "  3%|█▎                                        | 16/500 [00:45<22:30,  2.79s/it]-----------------------------------------------\n",
      "\n",
      "Image name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/ch4_test_images/img_113.jpg\n",
      "\n",
      "Annotation name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/Challenge4_Test_Task4_GT/gt_img_113.txt\n",
      "\n",
      "['###', '###', '###', '###', 'SALE', 'SAL', '###', 'SALE', '###', 'sale', '###', '###', '###', '###', '###', '###', '###', '###', '###', '###']\n",
      "\n",
      "Predicted texts: ['eE']\n",
      "\n",
      "res:  (0, 20, 4, 0, 0)\n",
      "Image true word count: 0\n",
      "Image not ignored word count: 4\n",
      "Image word accuracy (for not ignored): 0.0\n",
      "Levenshtein distance: 0\n",
      "\n",
      "  3%|█▍                                        | 17/500 [00:48<23:08,  2.87s/it]-----------------------------------------------\n",
      "\n",
      "Image name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/ch4_test_images/img_114.jpg\n",
      "\n",
      "Annotation name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/Challenge4_Test_Task4_GT/gt_img_114.txt\n",
      "\n",
      "['H&M', '###', 'FINAL', '###', 'SALE', 'FINAL', 'SAL', 'FINAL', '###', 'FARN', '###', '###', '###', '###']\n",
      "\n",
      "Predicted texts: []\n",
      "\n",
      "res:  (0, 0, 7, 0, 0)\n",
      "Image true word count: 0\n",
      "Image not ignored word count: 7\n",
      "Image word accuracy (for not ignored): 0.0\n",
      "Levenshtein distance: 0\n",
      "\n",
      "  4%|█▌                                        | 18/500 [00:49<19:57,  2.48s/it]-----------------------------------------------\n",
      "\n",
      "Image name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/ch4_test_images/img_115.jpg\n",
      "\n",
      "Annotation name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/Challenge4_Test_Task4_GT/gt_img_115.txt\n",
      "\n",
      "['SWEATS', 'COMFORTABLE', 'YERSATIUITT', 'DEFINED', 'HARA', '###']\n",
      "\n",
      "Predicted texts: ['d', 'de']\n",
      "\n",
      "res:  (1, 8, 5, 0, 0.9090909090909091)\n",
      "Image true word count: 0\n",
      "Image not ignored word count: 5\n",
      "Image word accuracy (for not ignored): 0.0\n",
      "Levenshtein distance: 0.9090909090909091\n",
      "\n",
      "  4%|█▌                                        | 19/500 [00:52<21:11,  2.64s/it]-----------------------------------------------\n",
      "\n",
      "Image name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/ch4_test_images/img_116.jpg\n",
      "\n",
      "Annotation name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/Challenge4_Test_Task4_GT/gt_img_116.txt\n",
      "\n",
      "['FOSSIL', 'UNI', 'QLO', '###', '###', '###', '###']\n",
      "\n",
      "Predicted texts: []\n",
      "\n",
      "res:  (0, 0, 3, 0, 0)\n",
      "Image true word count: 0\n",
      "Image not ignored word count: 3\n",
      "Image word accuracy (for not ignored): 0.0\n",
      "Levenshtein distance: 0\n",
      "\n",
      "  4%|█▋                                        | 20/500 [00:54<18:27,  2.31s/it]-----------------------------------------------\n",
      "\n",
      "Image name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/ch4_test_images/img_117.jpg\n",
      "\n",
      "Annotation name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/Challenge4_Test_Task4_GT/gt_img_117.txt\n",
      "\n",
      "['###', 'SELANGOR', '###', '###', '###', '###', '###']\n",
      "\n",
      "Predicted texts: ['POO']\n",
      "\n",
      "res:  (0, 7, 1, 0, 0)\n",
      "Image true word count: 0\n",
      "Image not ignored word count: 1\n",
      "Image word accuracy (for not ignored): 0.0\n",
      "Levenshtein distance: 0\n",
      "\n",
      "  4%|█▊                                        | 21/500 [00:57<20:11,  2.53s/it]-----------------------------------------------\n",
      "\n",
      "Image name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/ch4_test_images/img_118.jpg\n",
      "\n",
      "Annotation name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/Challenge4_Test_Task4_GT/gt_img_118.txt\n",
      "\n",
      "['TISSOT', 'TISSOT', '###', '###', '###', '###']\n",
      "\n",
      "Predicted texts: []\n",
      "\n",
      "res:  (0, 0, 2, 0, 0)\n",
      "Image true word count: 0\n",
      "Image not ignored word count: 2\n",
      "Image word accuracy (for not ignored): 0.0\n",
      "Levenshtein distance: 0\n",
      "\n",
      "  4%|█▊                                        | 22/500 [00:58<17:47,  2.23s/it]-----------------------------------------------\n",
      "\n",
      "Image name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/ch4_test_images/img_119.jpg\n",
      "\n",
      "Annotation name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/Challenge4_Test_Task4_GT/gt_img_119.txt\n",
      "\n",
      "['Robert', 'Timms', 'Robert', 'Timms', '###', '###']\n",
      "\n",
      "Predicted texts: ['oberTom']\n",
      "\n",
      "res:  (0, 6, 4, 0, 0)\n",
      "Image true word count: 0\n",
      "Image not ignored word count: 4\n",
      "Image word accuracy (for not ignored): 0.0\n",
      "Levenshtein distance: 0\n",
      "\n",
      "  5%|█▉                                        | 23/500 [01:02<19:46,  2.49s/it]-----------------------------------------------\n",
      "\n",
      "Image name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/ch4_test_images/img_12.jpg\n",
      "\n",
      "Annotation name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/Challenge4_Test_Task4_GT/gt_img_12.txt\n",
      "\n",
      "['###', '###', 'those', '###', 'need!', 'Care', 'for', 'Look', '###', '###', 'Care', '###', '###', '###', '###', '###']\n",
      "\n",
      "Predicted texts: ['oaae']\n",
      "\n",
      "res:  (0, 16, 6, 0, 0)\n",
      "Image true word count: 0\n",
      "Image not ignored word count: 6\n",
      "Image word accuracy (for not ignored): 0.0\n",
      "Levenshtein distance: 0\n",
      "\n",
      "  5%|██                                        | 24/500 [01:05<20:59,  2.65s/it]-----------------------------------------------\n",
      "\n",
      "Image name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/ch4_test_images/img_120.jpg\n",
      "\n",
      "Annotation name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/Challenge4_Test_Task4_GT/gt_img_120.txt\n",
      "\n",
      "['###', '###', '###', '###', '###', '###', '###', 'SINCERE', '###', '###', '###', '###', '###', '###', '###', '###']\n",
      "\n",
      "Predicted texts: ['BREIEO']\n",
      "\n",
      "res:  (1, 7, 1, 0, 0.8571428571428571)\n",
      "Image true word count: 0\n",
      "Image not ignored word count: 1\n",
      "Image word accuracy (for not ignored): 0.0\n",
      "Levenshtein distance: 0.8571428571428571\n",
      "\n",
      "  5%|██                                        | 25/500 [01:08<21:49,  2.76s/it]-----------------------------------------------\n",
      "\n",
      "Image name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/ch4_test_images/img_121.jpg\n",
      "\n",
      "Annotation name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/Challenge4_Test_Task4_GT/gt_img_121.txt\n",
      "\n",
      "['ESPRIT', '###', 'Enjoy', 'great', 'deals', 'privileges', 'Suntec', 'exciting', 'SINCERE', 'City', '###', '###', '###', '###', '###', '###', '###', '###', 'that', 'gives', 'you']\n",
      "\n",
      "Predicted texts: ['coltine', 'aCNt', '', 'tap', 'iE']\n",
      "\n",
      "res:  (1, 91, 12, 0, 0.625)\n",
      "Image true word count: 0\n",
      "Image not ignored word count: 12\n",
      "Image word accuracy (for not ignored): 0.0\n",
      "Levenshtein distance: 0.625\n",
      "\n",
      "  5%|██▏                                       | 26/500 [01:11<22:49,  2.89s/it]-----------------------------------------------\n",
      "\n",
      "Image name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/ch4_test_images/img_122.jpg\n",
      "\n",
      "Annotation name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/Challenge4_Test_Task4_GT/gt_img_122.txt\n",
      "\n",
      "['###', '###', 'SALE', 'FURTHER', 'REDUCTIONS', 'GIORDAN', '###', 'GAP', '###', '###', '###', '###', 'OFF', '###', '###', 'OFF', '###', 'COM', '###', '###', '###', '###']\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted texts: ['G6', 'L']\n",
      "\n",
      "res:  (1, 27, 8, 0, 1.0)\n",
      "Image true word count: 0\n",
      "Image not ignored word count: 8\n",
      "Image word accuracy (for not ignored): 0.0\n",
      "Levenshtein distance: 1.0\n",
      "\n",
      "  5%|██▎                                       | 27/500 [01:14<23:22,  2.97s/it]-----------------------------------------------\n",
      "\n",
      "Image name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/ch4_test_images/img_123.jpg\n",
      "\n",
      "Annotation name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/Challenge4_Test_Task4_GT/gt_img_123.txt\n",
      "\n",
      "['GIORDANO', '###', '###', '###']\n",
      "\n",
      "Predicted texts: ['StoTe', 'A', 'i']\n",
      "\n",
      "res:  (1, 8, 1, 0, 0.875)\n",
      "Image true word count: 0\n",
      "Image not ignored word count: 1\n",
      "Image word accuracy (for not ignored): 0.0\n",
      "Levenshtein distance: 0.875\n",
      "\n",
      "  6%|██▎                                       | 28/500 [01:17<23:34,  3.00s/it]-----------------------------------------------\n",
      "\n",
      "Image name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/ch4_test_images/img_124.jpg\n",
      "\n",
      "Annotation name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/Challenge4_Test_Task4_GT/gt_img_124.txt\n",
      "\n",
      "['###', '###', '###', '###', '###', '###', '###']\n",
      "\n",
      "Predicted texts: ['VILE']\n",
      "\n",
      "res:  (0, 7, 0, 0, 0)\n",
      "Image true word count: 0\n",
      "Image not ignored word count: 0\n",
      "Image word accuracy (for not ignored): all ignored\n",
      "Levenshtein distance: 0\n",
      "\n",
      "  6%|██▍                                       | 29/500 [01:20<23:49,  3.03s/it]-----------------------------------------------\n",
      "\n",
      "Image name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/ch4_test_images/img_125.jpg\n",
      "\n",
      "Annotation name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/Challenge4_Test_Task4_GT/gt_img_125.txt\n",
      "\n",
      "['###', 'sale', 'cafes', 'and', 'Restaurants', 'shops', 'food', 'more', 'republic', 'giant', 'hyperfresh', 'fountain', '###', '###', 'suntec', 'Money', 'Chang', 'office', 'SALE', 'SALE', 'COTTON', '###', '###', '###', '###', 'new', 'NOW', '###', '###', '###', '###', '###', '###', '###']\n",
      "\n",
      "Predicted texts: ['TOO', 'AR', 'aen', 'd', 'ti', '', 'd']\n",
      "\n",
      "res:  (3, 177, 20, 0, 3.0)\n",
      "Image true word count: 0\n",
      "Image not ignored word count: 20\n",
      "Image word accuracy (for not ignored): 0.0\n",
      "Levenshtein distance: 1.0\n",
      "\n",
      "  6%|██▌                                       | 30/500 [01:24<24:38,  3.15s/it]-----------------------------------------------\n",
      "\n",
      "Image name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/ch4_test_images/img_126.jpg\n",
      "\n",
      "Annotation name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/Challenge4_Test_Task4_GT/gt_img_126.txt\n",
      "\n",
      "['dining', 'and', 'continues', '###', 'shopping', 'remaking', 'city', 'you', 'for', 'your', 'support', '###', '###', '###', '###']\n",
      "\n",
      "Predicted texts: ['JOryousum']\n",
      "\n",
      "res:  (0, 15, 10, 0, 0)\n",
      "Image true word count: 0\n",
      "Image not ignored word count: 10\n",
      "Image word accuracy (for not ignored): 0.0\n",
      "Levenshtein distance: 0\n",
      "\n",
      "  6%|██▌                                       | 31/500 [01:27<24:29,  3.13s/it]-----------------------------------------------\n",
      "\n",
      "Image name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/ch4_test_images/img_127.jpg\n",
      "\n",
      "Annotation name: /data/ivpaharitonov/ocr_datasets/ICDAR2015/Challenge4_Test_Task4_GT/gt_img_127.txt\n",
      "\n",
      "['SPECIAL', 'robinsons', 'SK-II', '###', '###', '###', '###', '###', '###']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 new_eval.py \\\n",
    "--model=\"/data/ivpaharitonov/checkpoints/saved_icdar_2017/FOTS/checkpoint-epoch015-loss-1.9341.pth.tar\" \\\n",
    "--image_dir=\"/data/ivpaharitonov/ocr_datasets/ICDAR2015/ch4_test_images/\" \\\n",
    "--output_img_dir=\"/data/dmivanov/end2end_OCR/results/finetune_ICDAR2015/img\" \\\n",
    "--annotation_dir=\"/data/ivpaharitonov/ocr_datasets/ICDAR2015/Challenge4_Test_Task4_GT/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Levenshtein import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.zeros(size=(2,5,5,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance(\"hello fsd\", \"hello fsd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.upsampling.Upsample"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.Upsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "up = torch.nn.Upsample(size=(int(input_size*0.5)+1, int(input_size*0.5)+1), mode='bilinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 3, 3])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "up(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3,4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: -O: not found\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.google.ru/url?sa=i&source=images&cd=&cad=rja&uact=8&ved=2ahUKEwjx2tSh2p7iAhWGmIsKHR1bBzYQjRx6BAgBEAU&url=https%3A%2F%2Fnews.sportbox.ru%2FVidy_sporta%2FFutbol%2FEvropejskie_chempionaty%2FItaliya%2Fspbnews_NI1020686_Krishtianu_Ronaldu_Ludi_zhdut_chto_ja_ne_zabju_penalti_ili_provalu_reshajushhij_match_no_eto_chast_mojej_zhizni&psig=AOvVaw2RSVrlgV5qnb63orwQ1D3m&ust=1558049885372887 -O ronaldu.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-05-16 02:42:21--  https://pixel.nymag.com/imgs/daily/selectall/2018/02/12/12-tony-hawk.w710.h473.jpg\n",
      "Resolving pixel.nymag.com (pixel.nymag.com)... 151.101.112.70\n",
      "Connecting to pixel.nymag.com (pixel.nymag.com)|151.101.112.70|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 107928 (105K) [image/jpeg]\n",
      "Saving to: ‘img.jpg’\n",
      "\n",
      "img.jpg             100%[===================>] 105.40K  --.-KB/s    in 0.1s    \n",
      "\n",
      "2019-05-16 02:42:21 (1.07 MB/s) - ‘img.jpg’ saved [107928/107928]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://pixel.nymag.com/imgs/daily/selectall/2018/02/12/12-tony-hawk.w710.h473.jpg -O img.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('img.jpg')\n",
    "res = cv2.resize(img, dsize=(50, 100), interpolation=cv2.INTER_LINEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8b6920b358>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(res, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
